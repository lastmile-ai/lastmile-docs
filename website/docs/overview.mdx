---
id: overview
slug: /
---

import Tabs from "@theme/Tabs";
import TabItem from "@theme/TabItem";
import constants from "@site/core/tabConstants";

import { Card } from "@site/src/components/Card";
import { Grid } from "@site/src/components/Grid";
import { SplitPane } from "@site/src/components/SplitPane";
import { GettingStartedCard } from "@site/src/components/Home/GettingStartedCard";

# Introduction

LastMile is the full-stack developer platform to debug, evaluate and <u>improve</u> LLM applications. We make it easy to fine-tune custom evaluators, set up guardrails & monitor app performance.

<GettingStartedCard
  defaultLanguage="python"
  codeBlocks={[
    {
      language: "python",
      code: `from lastmile import LastMile;
LastMile.eval("Hello world")`,
    },
    {
      language: "javascript",
      label: "node.js",
      code: `const { LastMile } = require('lastmile');
LastMile.eval("Hello world");`,
    },
  ]}
/>

## Meet alBERTa üçÅ

alBERTa is a family of small language models designed for evaluation. They are optimized to be:

- **small** -- 400M parameter entailment model
- **fast** -- can run inference on CPU in < 300ms
- **customizable** -- fine-tune for custom evaluation tasks

<Grid className="alberta-grid">
  <Card
    href="/autoeval/models"
    title="alBERTa-512 üçÅ"
    description="2048 token context, specialized for evaluation tasks (like faithfulness), and gives a numeric 0->1 score."
    backgroundColor="#F5F5F5"
    className="custom-card model-512"
  />
  <Card
    href="/autoeval/models"
    title="alBERTa-LC-8k üçÅ"
    description="Long-context window variant that can scale to 128k+ tokens using a scaled dot-product attention layer"
    backgroundColor="#F5F5F5"
    className="custom-card model-8k"
  />
</Grid>

### Out-of-the-box metrics

<!-- Batteries-included evaluation metrics covering common AI application types, such as RAG and multi-agent compound AI systems. -->

<Grid className="custom-grid">
  <Card
    href="/autoeval/metrics"
    title="Faithfulness"
    description="Measures how adherent or faithful an LLM response is to the provided context. Often used for hallucination detection."
    className="custom-card faithfulness"
  />
  <Card
    href="/autoeval/metrics"
    title="Semantic Similarity"
    description="Measures semantic similarity between two strings. Often used for context relevance, or input/output relevance, or similarity between a response and ground truth."
    className="custom-card similarity"
  />
  <Card
    href="/autoeval/metrics"
    title="Summarization Quality"
    description="Quantify the quality of a summarization response."
    className="custom-card summarization"
  />
  <Card
    href="/autoeval/metrics"
    title="Toxicity"
    description="Quantify the toxicity level in an LLM response."
    className="custom-card toxicity"
  />
  <Card
    href="/autoeval/metrics"
    title="More"
    description="Explore other metrics available in AutoEval, or keep reading to design your own metric."
    className="custom-card"
  />
</Grid>

## Design your own metric

<!-- Use the fine-tuning service to design your own evaluators that represent custom criteria for your app quality. -->

<Grid className="custom-grid customize">
  <Card
    href="/autoeval/datasets"
    title="1. Create Datasets"
    description="Upload and manage application data for running and training evals, and generate synthetic labels."
    className="custom-card datasets"
  />
  <Card
    href="/autoeval/labeling"
    title="2. LLM Judge Active Labeling"
    description="Generate high-quality labels for your data using LLM Judge with human-in-the-loop"
    className="custom-card labeling"
  />
  <Card
    href="/autoeval/fine-tune"
    title="3. Fine-tune Models"
    description="Use the AutoEval fine-tuning service to develop custom metrics for your application."
    className="custom-card fine-tune"
  />
  <Card
    href="/autoeval/models"
    title="4. Run Evals"
    description="Compute metrics by running high-performance inference on a prebuilt or fine-tuned model."
    className="custom-card models"
  />
</Grid>

## Explore our guides

<Grid className="guides-grid">
  <Card
    href="/guides/rag-evaluation"
    title="Retrieval systems"
    description="Evaluate a RAG application for hallucination, relevance and a custom brand tone metric."
    className="custom-card"
  />
  <Card
    href="/guides/multi-agent-evaluation"
    title="Multi-agent applications"
    description="Evaluate end-to-end and intermediate step metrics for a compound AI system."
    className="custom-card"
  />
  <Card
    href="/guides/guardrails-guide"
    title="Real-time guardrails"
    description="Use alBERTa üçÅ model inference for real-time use-cases, like guardrails."
    className="custom-card"
  />
</Grid>
