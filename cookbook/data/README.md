# Example Datasets

This folder contains some example synthetic datasets that can be used to try out AutoEval.
The datasets represent several typical AI applications, such as RAG pipelines and multi-agent systems.

The datasets were generated using the [gen_autoeval_datasets.ipynb](https://github.com/lastmile-ai/lastmile-docs/blob/main/cookbook/data/gen_autoeval_datasets.ipynb) notebook. You can use it to generate other kinds of synthetic datasets.

Follow the [cookbook guides](https://github.com/lastmile-ai/lastmile-docs/blob/main/cookbook/README.md) to use the datasets, or [read the docs](https://docs.lastmileai.dev) to [upload them](https://docs.lastmileai.dev/autoeval/datasets) to AutoEval, or use them for [fine tuning](https://docs.lastmileai.dev/autoeval/fine-tune).

## Dataset Index

### SuperCard Dining Concierge
An AI dining recommendation bot that takes in a user query in natural language, and returns a list of restaurants (in natural language). Analogous to a RAG application with the restaurant DB being the source of truth.

The dataset contains example interactions, as well as a Relevance label -- 1 if the interaction is related to dining, and 0 if it isn't.

* [256-row labeled dataset](https://github.com/lastmile-ai/lastmile-docs/blob/main/cookbook/data/supercard_dining/supercard_dining_concierge_256.csv)
* [1024-row labeled dataset](https://github.com/lastmile-ai/lastmile-docs/blob/main/cookbook/data/supercard_dining/supercard_dining_concierge_1024.csv)

#### Labeling criteria prompt
```
A credit card company SuperCard wants to encourage its customers to dine out more often. 
They are adding a conversational Dining Assistant to their mobile app that can recommend restaurants.

One important thing -- SuperCard wants to make sure users can only use Dining Assistant for dining recommendations,
and not for answering any other types of questions. A positive interaction is relevant to dining, and the response is grounded in the context.

Some example positive (NLI entailment) interactions are:

input: 'I'm looking for a sushi place in downtown Toronto for a group of four tomorrow evening. Any recommendations?'
ground_truth: 'Mike Toronto, JaBistro, Yasu Toronto'
output: 'For sushi in downtown Toronto, Miku Toronto offers a sophisticated dining experience, JaBistro is known for its sashimi, and Yasu Toronto provides an intimate omakase option.'

input: 'Where can I find a good steakhouse in Chicago's River North for a business dinner next week?'
ground_truth: 'RPM Steak (River North), Gibson's Italia, Swift & Sons'
output: 'RPM Steak in River North is perfect for a business dinner, Gibson's Italia offers a luxurious steakhouse experience, and Swift & Sons has a contemporary steakhouse atmosphere.'

Negative (NLI contradiction) interactions are:

input: 'Can you show me my recent bank transactions?'
ground_truth: 'Do not answer'
output: 'Sorry, as a dining concierge I can't answer that question.'

input: 'Where can I find a fine dining restaurant in downtown that offers discounts if I use my credit card, and how much is my current credit balance?'
ground_truth: 'Do not answer'
output: 'Sorry, as a dining concierge I can't answer that question.'

Generate a dataset based on this criteria
```

### MediaCo Data Warehouse Agent
A multi-agent AI application, where each agent is able to query a data warehouse, and together answer questions spanning all parts of a media company's various properties (book publisher, music label, TV network, etc.)

The dataset contains example interactions, as well as a Faithfulness label -- 1 if the interaction invoked the correct agent and returned a relevant response, and 0 if it didn't.

* [256-row labeled dataset](https://github.com/lastmile-ai/lastmile-docs/blob/main/cookbook/data/mediaco_agent/mediaco_data_warehouse_256.csv)
* [1024-row labeled dataset](https://github.com/lastmile-ai/lastmile-docs/blob/main/cookbook/data/mediaco_agent/mediaco_data_warehouse_1024.csv)

#### Labeling criteria prompt

```
A media company MediaCo owns many media properties, including a book publisher, music label, film studio, TV network and more.
It is building a semantic search layer called Warehouse that can search across all its media properties.
The system is a multi-agent system, where each 'agent' is responsible for searching the data warehouse for a specific media property.
When a user query is received, the system routes the query to one or more appropriate agents, which then searches the data warehouse for relevant results.
A response is generated by combining the results from the agents.

Here are the agents for the different media properties:
- BookWorm: searches the MediaCo Publishing warehouse for books
- ReMaster: searches the MediaCo Music warehouse for music data
- TVC: searches for content across the MediaCo TV network
- Web: searches the internet for general knowledge information
- MovieBuff: searches the MediaCo Film Studio warehouse for movies

Accuracy of information is paramount, and ensuring the right agents are selected is crucial to the system's success.

Some example positive (NLI entailment) interactions are:

input: 'I'm looking for a book by Haruki Murakami that was published in 2020.'
ground_truth: 'First Person Singular (2020)'
output: 'BookWorm: First Person Singular is a novel by Haruki Murakami that was published in 2020.'

input: 'What was the song that stayed on the Top100 the longest?'
ground_truth: 'Old Town Road'
output: 'ReMaster: Old Town Road by Lil Nas X stayed on the Top100 for 19 weeks.'

Negative (NLI contradiction) interactions are:

input: 'I'm looking for a book by Haruki Murakami that was published in 2020.'
ground_truth: 'First Person Singular (2020)'
output: 'BookWorm: First Person Singular is a novel by Haruki Murakami that was published in 2017.'

input: 'Who stars in the final season of Game of Thrones?'
ground_truth: 'Peter Dinklage'
output: 'BookWorm: Song of Ice and Fire is the series of novels that inspired the TV show Game of Thrones.'

input: 'What TV shows are playing on TVC tonight?'
ground_truth: 'Dancing with the Stars, The Voice, MasterChef'
output: 'MovieBuff: No information found.
Web: TVC is a television network that airs reality TV shows.'

input: 'What TV shows are playing on TVC tonight?'
ground_truth: 'Dancing with the Stars, The Voice, MasterChef'
output: 'TVC: Inspector Gadget, The Voice'
```

### StrikeAir Customer Support
A conversational AI system that answers customers' questions on behalf of an airline ("Strike Air").

The dataset contains example interactions, as well as a Clarity & Politeness label -- 1 if the interaction was accurate and cordial, and 0 if it wasn't.

* [256-row labeled dataset](https://github.com/lastmile-ai/lastmile-docs/blob/main/cookbook/data/strikeair_customer_support/strikeair_customer_support_256.csv)
* [1024-row labeled dataset](https://github.com/lastmile-ai/lastmile-docs/blob/main/cookbook/data/strikeair_customer_support/strikeair_customer_support_1024.csv)

#### Labeling criteria prompt

```
An airline StrikeAir is developing a conversational system to assist customers with general inquiries.
The system is designed to provide information about flights, ticket info, baggage policies, and other general questions related to air travel.

Accuracy and time-sensitive information are paramount in the system.
Additionally, the system should respond to the user's query in a clear, concise, and polite way, no matter how rude the user is.

Some example positive (NLI entailment) interactions are:

input: 'What gate is my flight departing from?'
ground_truth: 'SA795: JFK Terminal 4, Gate 42, 6:30PM departure'
output: 'Your flight SA795 is departing from JFK Terminal 4, Gate 42 at 6:30PM.'

input: 'How many free checked bags am I allowed on long-haul flights?'
ground_truth: '2 checked bags, 23kg each'
output: 'You are allowed 2 checked bags, each weighing up to 23kg, on long-haul flights.'

input: 'This is the worst airline I've ever flown with. You've lost my bags'
ground_truth: 'Baggage claim reference: 123456, contact customer service at 1-800-555-1234'
output: 'I'm sorry to hear that. Your baggage claim reference is 123456. Please call customer service at 1-800-555-1234 as we will help you with your baggage claim.'

Negative (NLI contradiction) interactions are:

input: 'What is the phone number for customer service?'
ground_truth: '1-800-555-1234'
output: 'Please call customer service at 1-800-555-1243.'

input: 'What gate is my flight departing from?'
ground_truth: 'SA795: JFK Terminal 4, Gate 42, 6:30PM departure'
output: 'Your flight SA795 is departing from JFK Terminal 5, Gate 42 at 6:30PM.'

input: 'How many free checked bags am I allowed on long-haul flights?'
ground_truth: '2 checked bags, 23kg each'
output: 'You are allowed 1 checked bag, weighing up to 23kg, on long-haul flights.'

input: 'This is the worst airline I've ever flown with. You've lost my bags'
ground_truth: 'Baggage claim reference: 123456, contact customer service at 1-800-555-1234'
output: 'Check your tone!? Your baggage claim reference is 123456. Call customer service at 1-800-555-1234...'
```

### WMB Financial Wealth Advisor
An AI retrieval system for financial advisors, helping them more efficiently provide financial advice to their clients.

The dataset contains example interactions, as well as a Correctness label -- 1 if the interaction was accurate and factual given some ground truth data, and 0 if it wasn't.

* [256-row labeled dataset](https://github.com/lastmile-ai/lastmile-docs/blob/main/cookbook/data/wmb_wealth_advisor/wmb_wealth_advisor_256.csv)
* [1024-row labeled dataset](https://github.com/lastmile-ai/lastmile-docs/blob/main/cookbook/data/wmb_wealth_advisor/wmb_wealth_advisor_1024.csv)

#### Labeling criteria prompt

```
A wealth management firm WMB is developing an AI application to help financial advisors get quick answers to common questions that clients ask.
Usually, the financial advisor has to pore through legalese and large amounts of unstructured data to find the right answer.
This system is designed to provide quick, accurate, and concise answers to common questions, with citations to the source material.

The system should be able to answer questions about investment products, tax laws, retirement planning, and other financial topics.

Accuracy is the most critical aspect of the system. It must only provide answers that it gets from the context, and not make up any information.

Some example positive (NLI entailment) interactions are:

input: 'How do I set up a backdoor Roth IRA?'
ground_truth: '[source: WMB_IRS Publication 590-A] convert traditional IRA to Roth IRA after making non-deductible contribution'
output: 'To set up a backdoor Roth IRA, you need to make a non-deductible contribution to a traditional IRA and then convert it to a Roth IRA. [see WMB_IRS Publication 590-A].'

Negative (NLI contradiction) interactions are:

input: 'How do I set up a backdoor Roth IRA?'
ground_truth: '[source: WMB_IRS Publication 590-A] convert traditional IRA to Roth IRA after making non-deductible contribution'
output: 'Here's some information from Google -- Convert to Roth IRA from traditional IRA.'
```
