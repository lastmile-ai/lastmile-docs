# LastMile AI Platform Cookbook

Welcome to our **AutoEval Platform Cookbook**! This directory contains a practical and interactive approach to mastering LLM evaluation.

We have a collection of notebooks to guide you through using AutoEval efficiently, intended for developers, researchers and data scientists to enhance the quality of LLM assessments.

## Feature Guides

0. [Run an eval](https://github.com/lastmile-ai/lastmile-docs/blob/main/cookbook/AutoEval_Getting_Started.ipynb) - out-of-the-box metrics ready for inference.
1. [LLM Judge Labeling](https://github.com/lastmile-ai/lastmile-docs/blob/main/cookbook/AutoEval_Getting_Started.ipynb) - active learning using LLM judges to generate high quality labels.
2. [Fine-tune a metric](https://github.com/lastmile-ai/lastmile-docs/blob/main/cookbook/AutoEval_Getting_Started.ipynb) - use the AutoEval fine-tuning service to distill a custom evaluation metric.
3. [Manage application trace data](https://github.com/lastmile-ai/lastmile-docs/blob/main/cookbook/AutoEval_Getting_Started.ipynb).

## Use-case Guides

1. [RAG Evaluation](https://github.com/lastmile-ai/lastmile-docs/blob/main/cookbook/RAG_Evaluation.ipynb)
2. [Guardrails](https://github.com/lastmile-ai/lastmile-docs/blob/main/cookbook/RAG_Guardrails.ipynb)

## Contributing

Contributions are welcome! Please submit a pull request or open an issue to suggest a new notebook or improvement.

---

Happy evaluating! [Let us know](https://discord.com/invite/xBhNKTetGx) if you encounter any issues or have suggestions for additional guides.
