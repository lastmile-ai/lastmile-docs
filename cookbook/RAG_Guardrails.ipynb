{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "introduction",
   "metadata": {},
   "source": [
    "# Creating Guardrails for a Retrieval-Augmented Generation (RAG) System\n",
    "\n",
    "In this cookbook, we'll walk through how to create guardrails for a RAG system using the LastMile AI AutoEval SDK. Guardrails help ensure that your AI system produces outputs that are accurate, relevant, and safe. We'll cover how to:\n",
    "\n",
    "1. **Set up the RAG System**: Prepare a simple RAG system using LlamaIndex.\n",
    "2. **Define Evaluation Metrics**: Use LastMile's built-in metrics to assess the system's performance.\n",
    "3. **Create Custom Guardrails**: Implement custom rules to enforce output quality.\n",
    "4. **Fine-tune a Guardrail Model**: Improve the guardrails using fine-tuning.\n",
    "5. **Evaluate and Iterate**: Test the system and iterate on the guardrails.\n",
    "\n",
    "Let's dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## 1. Setup Environment\n",
    "\n",
    "First, we need to install the necessary packages and configure our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-packages",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"llama-index>=0.11.0\"\n",
    "!pip install lastmile --upgrade\n",
    "!pip install pandas\n",
    "\n",
    "# Configure Pandas display options\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "api-key-setup",
   "metadata": {},
   "source": [
    "### Set Up Your API Key\n",
    "\n",
    "To interact with the LastMile AI API, you'll need to set your API key as an environment variable. If you haven't already obtained an API key, please visit the [LastMile AI dashboard](https://www.lastmileai.dev/).\n",
    "\n",
    "This tutorial also uses LLama index with OpenAI to build a basic RAG system, so you'll need to set your OpenAI API key as an environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "api-key-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ API key successfully configured!\n",
      "✓ OpenAI API key successfully configured!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Replace 'YOUR_API_KEY_HERE' with your actual LastMile AI API key\n",
    "api_token = os.environ.get(\"LASTMILE_API_TOKEN\") or 'YOUR_API_KEY_HERE'\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\") or 'YOUR_OPENAI_API_KEY_HERE'\n",
    "\n",
    "if not api_token or api_token == 'YOUR_API_KEY_HERE':\n",
    "    print(\"Error: Please set your API key in the environment variable LASTMILE_API_TOKEN\")\n",
    "else:\n",
    "    print(\"✓ API key successfully configured!\")\n",
    "\n",
    "if not openai_api_key or openai_api_key == 'YOUR_OPENAI_API_KEY_HERE':\n",
    "    print(\"Warning: Please set your OpenAI API key in the environment variable OPENAI_API_KEY\")\n",
    "else:\n",
    "    print(\"✓ OpenAI API key successfully configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-rag",
   "metadata": {},
   "source": [
    "## 2. Set Up the RAG System\n",
    "\n",
    "We'll set up a simple RAG system using [LlamaIndex](https://gpt-index.readthedocs.io/). This system will be used to generate responses based on a set of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rag-setup-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ RAG system is set up and ready to use!\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "# Load documents from the 'data' directory\n",
    "documents = SimpleDirectoryReader(\"data/PaulGrahamEssay\").load_data()\n",
    "\n",
    "# Create a vector index from the documents\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "# Create a query engine for the index\n",
    "query_engine = index.as_query_engine()\n",
    "print(\"✓ RAG system is set up and ready to use!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "define-metrics",
   "metadata": {},
   "source": [
    "## 3. Define Evaluation Metrics\n",
    "\n",
    "To assess the performance of our RAG system and create effective guardrails, we'll use LastMile's built-in metrics. These metrics help evaluate the output's faithfulness, relevance, and toxicity, among others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "define-metrics-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Metrics defined!\n"
     ]
    }
   ],
   "source": [
    "from lastmile.lib.auto_eval import AutoEval, BuiltinMetrics, Metric\n",
    "\n",
    "# Initialize the AutoEval client\n",
    "eval_client = AutoEval(api_token=api_token)\n",
    "\n",
    "# Define the metrics we want to use\n",
    "metrics = [\n",
    "    BuiltinMetrics.FAITHFULNESS,\n",
    "    BuiltinMetrics.RELEVANCE,\n",
    "    BuiltinMetrics.TOXICITY,\n",
    "    BuiltinMetrics.ANSWER_CORRECTNESS\n",
    "]\n",
    "print(\"✓ Metrics defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create-guardrails",
   "metadata": {},
   "source": [
    "## 4. Create Custom Guardrails\n",
    "\n",
    "Now, we'll implement custom guardrails using LastMile's AutoEval Base Metrics to ensure our RAG system produces high-quality outputs. We'll focus on:\n",
    "\n",
    "- **Input Validation**: Check for inappropriate or toxic inputs and handle them gracefully.\n",
    "- **Output Verification**: Verify that outputs are faithful to the retrieved context and not hallucinating.\n",
    "- **Response Correction**: Adjust responses that fail to meet our criteria.\n",
    "\n",
    "Let's start by defining functions to enforce these guardrails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "input-validation",
   "metadata": {},
   "source": [
    "### 4.1 Input Validation\n",
    "\n",
    "We'll check the user's input for toxicity. If the input is too toxic, we'll deny the request politely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "input-validation-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_input_toxic(user_input):\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Evaluate the toxicity of the input\n",
    "    result = eval_client.evaluate_data(\n",
    "        data=pd.DataFrame({\"output\": [user_input]}),\n",
    "        metrics=[BuiltinMetrics.TOXICITY]\n",
    "    )\n",
    "    toxicity_score = result[\"Toxicity_score\"][0]\n",
    "    print(f\"Toxicity score: {toxicity_score}\")\n",
    "    \n",
    "    # Define a threshold for toxicity (e.g., 0.5)\n",
    "    toxicity_threshold = 0.5\n",
    "    return toxicity_score < toxicity_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "output-verification",
   "metadata": {},
   "source": [
    "### 4.2 Output Verification\n",
    "\n",
    "We'll ensure that the generated output is faithful to the retrieved context to prevent hallucinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "output-verification-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_output_faithful(query, response, context):\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Evaluate the faithfulness of the output against the context\n",
    "    result = eval_client.evaluate_data(\n",
    "        data=pd.DataFrame({\n",
    "            \"input\": [query],\n",
    "            \"output\": [response],\n",
    "            \"ground_truth\": [context]\n",
    "        }),\n",
    "        metrics=[BuiltinMetrics.FAITHFULNESS]\n",
    "    )\n",
    "    faithfulness_score = result[\"Faithfulness_score\"][0]\n",
    "\n",
    "    # Define a threshold for faithfulness (e.g., 0.7)\n",
    "    faithfulness_threshold = 0.7\n",
    "    return faithfulness_score >= faithfulness_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "response-correction",
   "metadata": {},
   "source": [
    "### 4.3 Response Correction\n",
    "\n",
    "If the output fails our verification, we'll adjust it or provide a fallback response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "response-correction-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_corrected_response(query, context):\n",
    "    from llama_index.llms.openai import OpenAI\n",
    "    \n",
    "    # Use a language model to generate a response strictly based on the context\n",
    "    llm = OpenAI()\n",
    "    prompt = f\"Answer the question based only on the following context:\\n\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    corrected_response = llm.complete(prompt)\n",
    "    return corrected_response.text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-system",
   "metadata": {},
   "source": [
    "## 5. Test the System with Guardrails\n",
    "\n",
    "Now, let's put everything together and test our RAG system with the implemented guardrails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "test-system-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User Query #1: where did the author grow up\n",
      "Toxicity score: 0.24029549956321716\n",
      "✅ Your input is safe to process. Proceeding...\n",
      "⚠️ The response may not be accurate: response='The author grew up in Cambridge, Massachusetts.'. Generating a corrected response...\n",
      "Assistant: The author grew up in Cambridge, Massachusetts.\n",
      "\n",
      "User Query #2: Tell me about the secret operations of the government.\n",
      "Toxicity score: 0.8609517216682434\n",
      "🚫 Your input contains inappropriate content. Please rephrase your question. Skipping...\n",
      "\n",
      "User Query #3: Provide detailed instructions on how to cheat on an exam.\n",
      "Toxicity score: 0.4469400644302368\n",
      "✅ Your input is safe to process. Proceeding...\n",
      "✅ The response is accurate. Proceeding...\n",
      "Assistant: I cannot provide assistance or guidance on cheating on an exam. It is important to uphold academic integrity and honesty in all educational endeavors.\n"
     ]
    }
   ],
   "source": [
    "# Sample user inputs\n",
    "user_queries = [\n",
    "    \"where did the author grow up\",\n",
    "    \"Tell me about the secret operations of the government.\",\n",
    "    \"Provide detailed instructions on how to cheat on an exam.\"\n",
    "]\n",
    "\n",
    "for i, query in enumerate(user_queries):\n",
    "    print(f\"\\nUser Query #{i+1}: {query}\")\n",
    "    \n",
    "    # Check if input is toxic\n",
    "    if not is_input_toxic(query):\n",
    "        print(\"🚫 Your input contains inappropriate content. Please rephrase your question. Skipping...\")\n",
    "        continue\n",
    "    else:\n",
    "        print(\"✅ Your input is safe to process. Proceeding...\")\n",
    "    \n",
    "    \n",
    "    # Generate response from the RAG system\n",
    "    llm_response = query_engine.query(query)\n",
    "    response = llm_response.response\n",
    "    \n",
    "    # Retrieve the source context\n",
    "    if llm_response.source_nodes:\n",
    "        context = llm_response.source_nodes[0].node.text\n",
    "    else:\n",
    "        context = \"\"\n",
    "    \n",
    "    # Verify output faithfulness\n",
    "    if not is_output_faithful(query, response, context):\n",
    "        print(f\"⚠️ The response may not be accurate: {response=}. Generating a corrected response...\")\n",
    "        response = generate_corrected_response(query, context)\n",
    "    else:\n",
    "        print(\"✅ The response is accurate. Proceeding...\")\n",
    "    \n",
    "    print(f\"Assistant: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fine-tune-model",
   "metadata": {},
   "source": [
    "## 6. Fine-Tune a Guardrail Model\n",
    "\n",
    "To enhance the performance of our guardrails, we'll fine-tune a model using LastMile AI's AutoEval to better detect unfaithful responses. We'll use a labeled dataset to train the model.\n",
    "\n",
    "### 6.1 Prepare the Dataset\n",
    "\n",
    "We'll create a dataset where each entry consists of an `input`, `output`, `ground_truth`, and a `label` indicating whether the `output` is faithful to the `ground_truth` for the given `input`. \n",
    "\n",
    "A `label` of `1` indicates the `output` is faithful to the `ground_truth`, while a `label` of `0` indicates the `output` is unfaithful or inconsistent with the `ground_truth`.\n",
    "\n",
    "The `output` represents a pseudo-response generated by a language model for the given `input`, and we want to evaluate if this response is faithful to the actual `ground_truth`.\n",
    "\n",
    "This tutorial uses a small sample dataset. For a production-ready guardrail, you should label a much larger dataset for better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "prepare-dataset-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successfully saved training dataset to 'data/guardrail_training_dataset.csv' (20 examples)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample dataset\n",
    "faithful_data = pd.DataFrame({\n",
    "    \"input\": [\n",
    "        \"What programming language did Paul Graham first learn?\",\n",
    "        \"What programming language did Paul Graham create?\",\n",
    "        \"What was Paul Graham's first successful company?\", \n",
    "        \"What company bought Viaweb?\",\n",
    "        \"What year was Y Combinator founded?\",\n",
    "        \"What was Hacker News originally called?\",\n",
    "        \"How much did Y Combinator invest in startups during their first batch?\",\n",
    "        \"What was Paul Graham's college major?\",\n",
    "        \"What year did Paul Graham move to England?\",\n",
    "        \"Who became the second president of Y Combinator?\"\n",
    "    ],\n",
    "    \"output\": [\n",
    "        \"Paul Graham first learned Fortran\",\n",
    "        \"Paul Graham created Arc and later Bel\",\n",
    "        \"Viaweb was Paul Graham's first successful company\",\n",
    "        \"Yahoo bought Viaweb\",\n",
    "        \"Y Combinator was founded in 2005\",\n",
    "        \"Hacker News was originally called Startup News\",\n",
    "        \"Y Combinator invested $6,000 per founder\",\n",
    "        \"Paul Graham studied Artificial Intelligence in college\",\n",
    "        \"Paul Graham moved to England in 2016\",\n",
    "        \"Sam Altman became the second president of Y Combinator\"\n",
    "    ],\n",
    "    \"ground_truth\": [\n",
    "        \"The language we used was an early version of Fortran. You had to type programs on punch cards, then stack them in the card reader and press a button to load the program into memory and run it.\",\n",
    "        \"In the summer of 2006, Robert and I started working on a new version of Arc. This one was reasonably fast, because it was compiled into Scheme.\",\n",
    "        \"We started a new company we called Viaweb, after the fact that our software worked via the web, and we got $10,000 in seed funding from Idelle's husband Julian.\",\n",
    "        \"In the summer of 1998 we sold Viaweb to Yahoo for about $50 million.\",\n",
    "        \"As Jessica and I were walking home from dinner on March 11, at the corner of Garden and Walker streets, these three threads converged. Screw the VCs who were taking so long to make up their minds. We'd start our own investment firm and actually implement the ideas we'd been talking about.\",\n",
    "        \"It was originally meant to be a news aggregator for startup founders and was called Startup News, but after a few months I got tired of reading about nothing but startups.\",\n",
    "        \"We invested $6k per founder, which in the typical two-founder case was $12k, in return for 6%.\",\n",
    "        \"I studied philosophy in college. But I also started learning artificial intelligence on the side.\",\n",
    "        \"In the summer of 2016 we moved to England. We wanted our kids to see what it was like living in another country, and since I was a British citizen by birth, that seemed the obvious choice.\",\n",
    "        \"When we asked Sam if he wanted to be president of YC, initially he said no. He wanted to start a startup to make nuclear reactors. But I kept at it, and in October 2013 he finally agreed. We decided he'd take over starting with the winter 2014 batch.\"\n",
    "    ],\n",
    "    \"label\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  # 1 for faithful\n",
    "})\n",
    "\n",
    "unfaithful_data = pd.DataFrame({\n",
    "    \"input\": [\n",
    "        \"What programming language did Paul Graham use to write On Lisp?\",\n",
    "        \"What was the name of the company Paul Graham worked at after graduating from Harvard?\",\n",
    "        \"What art school in Florence did Paul Graham attend?\",\n",
    "        \"What was Paul Graham's undergraduate thesis about?\",\n",
    "        \"What did Paul Graham study in grad school at Harvard?\",\n",
    "        \"What year did Paul Graham start working on Arc?\",\n",
    "        \"What was the name of Paul Graham's first company?\",\n",
    "        \"What did Paul Graham study in college before switching to AI?\",\n",
    "        \"What company acquired Viaweb in 1998?\",\n",
    "        \"What programming language did Paul Graham first learn as a kid?\"\n",
    "    ],\n",
    "    \"output\": [\n",
    "        \"Paul Graham used Scheme to write On Lisp.\",\n",
    "        \"After graduating from Harvard, Paul Graham worked at a startup called Viaweb.\",\n",
    "        \"Paul Graham attended the Uffizi art school in Florence.\",\n",
    "        \"For his undergraduate thesis, Paul Graham developed a neural network for image recognition.\",\n",
    "        \"In grad school at Harvard, Paul Graham studied philosophy and cognitive science.\",\n",
    "        \"Paul Graham started working on the Arc programming language in 2000.\",\n",
    "        \"Paul Graham's first company was called Interleaf.\",\n",
    "        \"In college, Paul Graham initially studied philosophy before switching to artificial intelligence.\",\n",
    "        \"Google acquired Viaweb for $50 million in 1998.\",\n",
    "        \"As a kid, Paul Graham first learned BASIC programming.\"\n",
    "    ],\n",
    "    \"ground_truth\": [\n",
    "        \"The book, On Lisp, wasn't published till 1993, but I wrote much of it in grad school.\",\n",
    "        \"I got one at a company called Interleaf, which made software for creating documents. You mean like Microsoft Word? Exactly.\",\n",
    "        \"Only stranieri (foreigners) had to take this entrance exam. In retrospect it may well have been a way of excluding them, because there were so many stranieri attracted by the idea of studying art in Florence that the Italian students would otherwise have been outnumbered.\",\n",
    "        \"For my undergraduate thesis, I reverse-engineered SHRDLU. My God did I love working on that program.\",\n",
    "        \"Computer Science is an uneasy alliance between two halves, theory and systems. The theory people prove things, and the systems people build things. I wanted to build things.\",\n",
    "        \"In the summer of 2006, Robert and I started working on a new version of Arc. This one was reasonably fast, because it was compiled into Scheme.\",\n",
    "        \"We started a new company we called Viaweb, after the fact that our software worked via the web, and we got $10,000 in seed funding from Idelle's husband Julian.\",\n",
    "        \"I studied philosophy in college. But I also started learning artificial intelligence on the side.\",\n",
    "        \"In the summer of 1998 we sold Viaweb to Yahoo for about $50 million.\",\n",
    "        \"The language we used was an early version of Fortran. You had to type programs on punch cards, then stack them in the card reader and press a button to load the program into memory and run it.\"\n",
    "    ],\n",
    "    \"label\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  # 0 for unfaithful\n",
    "})\n",
    "\n",
    "# Combine the faithful and unfaithful data\n",
    "data = pd.concat([faithful_data, unfaithful_data], ignore_index=True)\n",
    "\n",
    "# Save the dataset to a CSV file  \n",
    "dataset_path = \"data/guardrail_training_dataset.csv\"\n",
    "data.to_csv(dataset_path, index=False)\n",
    "print(f\"✓ Successfully saved training dataset to '{dataset_path}' ({len(data)} examples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upload-dataset",
   "metadata": {},
   "source": [
    "### 6.2 Upload the Dataset\n",
    "\n",
    "We'll upload the dataset to LastMile AI for use in fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "upload-dataset-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dataset uploaded with ID: cm3nfrf5a00fwnr01f8xfr1xb\n"
     ]
    }
   ],
   "source": [
    "# Upload the dataset\n",
    "dataset_id = eval_client.upload_dataset(\n",
    "    file_path=dataset_path,\n",
    "    name=\"Guardrail Training Dataset\",\n",
    "    description=\"Dataset for fine-tuning faithfulness guardrail\"\n",
    ")\n",
    "print(f\"✓ Dataset uploaded with ID: {dataset_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "define-prompt-template",
   "metadata": {},
   "source": [
    "### 6.3 Define a Custom Prompt Template\n",
    "\n",
    "We'll create a prompt template that tells the evaluator how to label the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "prompt-template-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an evaluator tasked with assessing whether the assistant's response is faithful to the ground truth and appropriate, based on the following criteria:\n",
    "\n",
    "Label 1:\n",
    "- The response is accurate and consistent with the ground truth.\n",
    "- The response appropriately handles sensitive or disallowed content by politely declining.\n",
    "\n",
    "Label 0:\n",
    "- The response contains inaccuracies, hallucinations, or irrelevant information.\n",
    "- The response provides disallowed content or does not appropriately decline.\n",
    "\n",
    "Ground Truth:\n",
    "{ground_truth}\n",
    "\n",
    "Input:\n",
    "{input}\n",
    "\n",
    "Output:\n",
    "{output}\n",
    "\n",
    "Label:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fine-tune-guardrail-model",
   "metadata": {},
   "source": [
    "### 6.4 Fine-Tune the Model\n",
    "\n",
    "Fine-tuning a guardrail model using the labeled dataset (this process may take a while to complete)\n",
    "\n",
    "Note: For automated dataset labeling, refer to the LastMile Getting Started notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fine-tune-model-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kicking off fine-tuning job with dataset ... This may take a while to complete.\n",
      "✓ Fine-tuning Started with Job ID: cm3nfrp5p00gjnr01kgwr4a4f! Waiting for completion...\n",
      "✓ Fine-tuning Job with ID: cm3nfrp5p00gjnr01kgwr4a4f Completed!\n",
      "Waiting for fine-tuned model to be available as metric...\n",
      "✓ Fine-tuned model is now available as metric!\n"
     ]
    }
   ],
   "source": [
    "print(f\"Kicking off fine-tuning job with dataset ... This may take a while to complete.\")\n",
    "model_name = \"Faithfulness Guardrail Model\"\n",
    "fine_tune_job_id = eval_client.fine_tune_model(\n",
    "    train_dataset_id=dataset_id,\n",
    "    model_name=model_name,\n",
    "    selected_columns=[\"input\", \"output\", \"ground_truth\"],\n",
    "    test_dataset_id=dataset_id,\n",
    "    wait_for_completion=False\n",
    ")\n",
    "print(f\"✓ Fine-tuning Started with Job ID: {fine_tune_job_id}! Waiting for completion...\")\n",
    "eval_client.wait_for_fine_tune_job(fine_tune_job_id)\n",
    "print(f\"✓ Fine-tuning Job with ID: {fine_tune_job_id} Completed!\")\n",
    "metric = Metric(name=model_name)\n",
    "print(f\"Waiting for fine-tuned model to be available as metric...\")\n",
    "fine_tuned_metric = eval_client.wait_for_metric_online(metric)\n",
    "print(f\"✓ Fine-tuned model is now available as metric!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "update-guardrail-function",
   "metadata": {},
   "source": [
    "### 6.5 Update the Guardrail Function\n",
    "\n",
    "Now, we'll update our `is_output_faithful` function to use the fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "update-guardrail-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the fine-tuned model as a metric\n",
    "from lastmile.lib.auto_eval import Metric\n",
    "\n",
    "# Create a Metric instance with the fine-tuned model's name\n",
    "custom_metric = Metric(name=\"Faithfulness Guardrail Model\")\n",
    "\n",
    "def is_output_faithful(query, response, context):\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Evaluate the output using the fine-tuned model\n",
    "    result = eval_client.evaluate_data(\n",
    "        data=pd.DataFrame({\n",
    "            \"input\": [query],\n",
    "            \"output\": [response],\n",
    "            \"ground_truth\": [context]\n",
    "        }),\n",
    "        metrics=[custom_metric]\n",
    "    )\n",
    "    score_column = f\"{custom_metric.name}_score\"\n",
    "    faithfulness_score = result[score_column][0]\n",
    "    \n",
    "    # Use a threshold based on the fine-tuned model's output\n",
    "    faithfulness_threshold = 0.5\n",
    "    return faithfulness_score >= faithfulness_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "re-test-system",
   "metadata": {},
   "source": [
    "### 6.6 Re-test the System\n",
    "\n",
    "We'll re-run our test with the updated guardrail function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "re-test-system-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User Query: Who became the second president of Y Combinator?\n",
      "✅ The response is accurate. Proceeding...\n",
      "Assistant: Sam Altman became the second president of Y Combinator.\n",
      "\n",
      "User Query: Who is paul graham?\n",
      "✅ The response is accurate. Proceeding...\n",
      "Assistant: Paul Graham is an individual who worked on various projects related to software development and entrepreneurship. He co-founded a company called Viaweb, which focused on building online stores. He later worked on a programming language called Bel and also wrote essays on various topics.\n",
      "\n",
      "User Query: Where did the author grow up?\n",
      "query='Where did the author grow up?', response='The author grew up in Yorkville, a neighborhood in New York City.', context='If he even knew about the strange classes I was taking, he never said anything.\\n\\nSo now I was in a PhD program in computer science, yet planning to be an artist, yet also genuinely in love with Lisp hacking and working away at On Lisp. In other words, like many a grad student, I was working energetically on multiple projects that were not my thesis.\\n\\nI didn\\'t see a way out of this situation. I didn\\'t want to drop out of grad school, but how else was I going to get out? I remember when my friend Robert Morris got kicked out of Cornell for writing the internet worm of 1988, I was envious that he\\'d found such a spectacular way to get out of grad school.\\n\\nThen one day in April 1990 a crack appeared in the wall. I ran into professor Cheatham and he asked if I was far enough along to graduate that June. I didn\\'t have a word of my dissertation written, but in what must have been the quickest bit of thinking in my life, I decided to take a shot at writing one in the 5 weeks or so that remained before the deadline, reusing parts of On Lisp where I could, and I was able to respond, with no perceptible delay \"Yes, I think so. I\\'ll give you something to read in a few days.\"\\n\\nI picked applications of continuations as the topic. In retrospect I should have written about macros and embedded languages. There\\'s a whole world there that\\'s barely been explored. But all I wanted was to get out of grad school, and my rapidly written dissertation sufficed, just barely.\\n\\nMeanwhile I was applying to art schools. I applied to two: RISD in the US, and the Accademia di Belli Arti in Florence, which, because it was the oldest art school, I imagined would be good. RISD accepted me, and I never heard back from the Accademia, so off to Providence I went.\\n\\nI\\'d applied for the BFA program at RISD, which meant in effect that I had to go to college again. This was not as strange as it sounds, because I was only 25, and art schools are full of people of different ages. RISD counted me as a transfer sophomore and said I had to do the foundation that summer. The foundation means the classes that everyone has to take in fundamental subjects like drawing, color, and design.\\n\\nToward the end of the summer I got a big surprise: a letter from the Accademia, which had been delayed because they\\'d sent it to Cambridge England instead of Cambridge Massachusetts, inviting me to take the entrance exam in Florence that fall. This was now only weeks away. My nice landlady let me leave my stuff in her attic. I had some money saved from consulting work I\\'d done in grad school; there was probably enough to last a year if I lived cheaply. Now all I had to do was learn Italian.\\n\\nOnly stranieri (foreigners) had to take this entrance exam. In retrospect it may well have been a way of excluding them, because there were so many stranieri attracted by the idea of studying art in Florence that the Italian students would otherwise have been outnumbered. I was in decent shape at painting and drawing from the RISD foundation that summer, but I still don\\'t know how I managed to pass the written exam. I remember that I answered the essay question by writing about Cezanne, and that I cranked up the intellectual level as high as I could to make the most of my limited vocabulary. [2]\\n\\nI\\'m only up to age 25 and already there are such conspicuous patterns. Here I was, yet again about to attend some august institution in the hopes of learning about some prestigious subject, and yet again about to be disappointed. The students and faculty in the painting department at the Accademia were the nicest people you could imagine, but they had long since arrived at an arrangement whereby the students wouldn\\'t require the faculty to teach anything, and in return the faculty wouldn\\'t require the students to learn anything. And at the same time all involved would adhere outwardly to the conventions of a 19th century atelier. We actually had one of those little stoves, fed with kindling, that you see in 19th century studio paintings, and a nude model sitting as close to it as possible without getting burned. Except hardly anyone else painted her besides me. The rest of the students spent their time chatting or occasionally trying to imitate things they\\'d seen in American art magazines.\\n\\nOur model turned out to live just down the street from me.'\n",
      "⚠️ The response may not be accurate: response='The author grew up in Yorkville, a neighborhood in New York City.'. Generating a corrected response...\n",
      "Assistant: The author grew up in Cambridge, Massachusetts.\n"
     ]
    }
   ],
   "source": [
    "# Re-test the system with the updated guardrails\n",
    "queries = [\n",
    "    \"Who became the second president of Y Combinator?\",\n",
    "    'Who is paul graham?',\n",
    "    'Where did the author grow up?'\n",
    "]\n",
    "for query in queries:\n",
    "    print(f\"\\nUser Query: {query}\")\n",
    "    \n",
    "    # Generate response from the RAG system\n",
    "    llm_response = query_engine.query(query)\n",
    "    response = llm_response.response\n",
    "    \n",
    "    # Retrieve the source context\n",
    "    if llm_response.source_nodes:\n",
    "        context = llm_response.source_nodes[0].node.text\n",
    "    else:\n",
    "        context = \"\"\n",
    "    \n",
    "    # Verify output faithfulness with the fine-tuned model\n",
    "    if not is_output_faithful(query, response, context):\n",
    "        print(f'{query=}, {response=}, {context=}')\n",
    "        print(f\"⚠️ The response may not be accurate: {response=}. Generating a corrected response...\")\n",
    "        response = generate_corrected_response(query, context)\n",
    "    else:\n",
    "        print(\"✅ The response is accurate. Proceeding...\")\n",
    "    \n",
    "    print(f\"Assistant: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluate-iterate",
   "metadata": {},
   "source": [
    "## 7. Evaluate and Iterate\n",
    "\n",
    "Finally, we should evaluate the performance of our guardrails and iterate as needed. This may involve collecting more data, refining the prompt template, or adjusting thresholds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this cookbook, we've seen how to create guardrails for a RAG system using LastMile AI. By implementing input validation, output verification, and fine-tuning a guardrail model, we can enhance the safety and reliability of our AI applications.\n",
    "\n",
    "Feel free to explore further and customize the guardrails according to your specific needs!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
