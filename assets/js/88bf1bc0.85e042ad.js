"use strict";(self.webpackChunklastmile_docs=self.webpackChunklastmile_docs||[]).push([[8599],{69967:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>r,default:()=>m,frontMatter:()=>o,metadata:()=>d,toc:()=>u});var i=t(74848),a=t(28453),s=t(4865),l=t(19365);t(79402);const o={id:"fine-tune",title:"Fine-tune Evaluators"},r="Evaluator Fine-tuning",d={id:"autoeval/fine-tune",title:"Fine-tune Evaluators",description:"Build your own evaluation metric by fine-tuning alBERTa evaluator models",source:"@site/docs/autoeval/fine-tuning.mdx",sourceDirName:"autoeval",slug:"/autoeval/fine-tune",permalink:"/autoeval/fine-tune",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{id:"fine-tune",title:"Fine-tune Evaluators"},sidebar:"sidebar",previous:{title:"Synthetic Labeling",permalink:"/autoeval/labeling"},next:{title:"Evaluator Models",permalink:"/autoeval/models"}},c={},u=[{value:"Why fine-tune?",id:"why-fine-tune",level:3},{value:"Usage Guide",id:"usage-guide",level:2},{value:"Upload Datasets",id:"upload-datasets",level:3},{value:"Label data",id:"label-data",level:3},{value:"Training and test data split (optional)",id:"training-and-test-data-split-optional",level:3},{value:"Fine-tune model",id:"fine-tune-model",level:3},{value:"API",id:"api",level:4},{value:"UI",id:"ui",level:4},{value:"Use fine-tuned model",id:"use-fine-tuned-model",level:3},{value:"API",id:"api-1",level:4},{value:"Weights &amp; Biases integration",id:"weights--biases-integration",level:3}];function h(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"evaluator-fine-tuning",children:"Evaluator Fine-tuning"})}),"\n",(0,i.jsxs)(n.p,{children:["Build your own evaluation metric by fine-tuning ",(0,i.jsx)(n.a,{href:"/autoeval/models",children:"alBERTa evaluator models"})]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"AutoEval Flow",src:t(59413).A+"",width:"1364",height:"202"})}),"\n",(0,i.jsx)(n.p,{children:"The AutoEval fine-tuning service enables you to develop models that represent your custom evaluation criteria. The flow is roughly as follows:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["Start with a ",(0,i.jsx)(n.a,{href:"/autoeval/datasets",children:"Dataset"})," of your application data."]}),"\n",(0,i.jsxs)(n.li,{children:["(Assuming you don't have labels) Specify your evaluation criteria and generate labels with ",(0,i.jsx)(n.a,{href:"/autoeval/labeling",children:"synthetic labeling"}),"."]}),"\n",(0,i.jsx)(n.li,{children:"Use the AutoEval fine-tuning service to train a fine-tuned evaluator model using the labeled data to learn the evaluation criteria."}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"The fine-tuned model will then produce a numeric 0->1 probability score for every request."}),"\n",(0,i.jsx)(n.p,{children:"Some example evaluators that AutoEval customers have trained:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["A custom ",(0,i.jsx)(n.strong,{children:"response quality"})," metric that includes succinctness, clarity, and accuracy."]}),"\n",(0,i.jsxs)(n.li,{children:["A custom ",(0,i.jsx)(n.strong,{children:"correctness metric"})," for tool use (function calling) in a multi-agent system."]}),"\n",(0,i.jsxs)(n.li,{children:["A custom ",(0,i.jsx)(n.strong,{children:"brand tone"})," metric to measure LLM response adherence to company's brand tone rubric."]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"why-fine-tune",children:"Why fine-tune?"}),"\n",(0,i.jsx)(n.p,{children:"Fine-tuning your own alBERTa evaluator model is much more effective than LLM Judge style eval approaches for a number of reasons.\nUnlike an LLM Judge, this model can be small, fast and include human-in-the-loop refinement:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"better metric quality"})," -- the quality of evaluations is bound by quality of the labels (which can be refined with human feedback), not bound by an LLM's ability to understand your application context."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"small & fast"})," -- 100x faster than LLM Judge (can run inference in 10-300ms), which allows these evaluators to run online as ",(0,i.jsx)(n.a,{href:"/autoeval/guardrails",children:"guardrails"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"customizable"})," -- the model is simply learning the label distribution, making it easy to teach it any kind of classification task."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"You can fine-tune as many evaluators as you want \u2013 one for each evaluation criteria you need for your application."}),"\n",(0,i.jsx)(n.h2,{id:"usage-guide",children:"Usage Guide"}),"\n",(0,i.jsx)(n.h3,{id:"upload-datasets",children:"Upload Datasets"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"/autoeval/datasets#create-a-new-dataset",children:"Create a Dataset"})," containing the application trace data to use for fine-tuning."]}),"\n",(0,i.jsx)(n.admonition,{type:"tip",children:(0,i.jsx)(n.p,{children:"We recommend at least a few hundred examples (256 minimum). A few thousand examples is ideal."})}),"\n",(0,i.jsx)(n.p,{children:"During the fine-tuning flow you can choose which of these columns to include in the training. Make sure that the data contains at least one of the following columns:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"input"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"output"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"ground_truth"})}),"\n"]}),"\n",(0,i.jsx)(n.admonition,{type:"tip",children:(0,i.jsxs)(n.p,{children:["Don't have app data handy? No problem - check out our ",(0,i.jsx)(n.a,{href:"/autoeval/datasets/example-datasets",children:"Example Datasets"})," to get synthetic datasets to try out the platform."]})}),"\n",(0,i.jsx)(n.h3,{id:"label-data",children:"Label data"}),"\n",(0,i.jsxs)(n.p,{children:["Use ",(0,i.jsx)(n.a,{href:"/autoeval/labeling#usage-guide",children:"synthetic labeling"})," flow to define your evaluation criteria and generate labels."]}),"\n",(0,i.jsx)(n.h3,{id:"training-and-test-data-split-optional",children:"Training and test data split (optional)"}),"\n",(0,i.jsx)(n.p,{children:"Split the dataset into a training dataset and a test (holdout) dataset."}),"\n",(0,i.jsx)(n.admonition,{type:"tip",children:(0,i.jsx)(n.p,{children:"We recommend an 80/20 or 90/10 split."})}),"\n",(0,i.jsxs)(n.p,{children:["You can do this via ",(0,i.jsx)(n.a,{href:"/sdk",children:"API"}),":"]}),"\n",(0,i.jsx)(s.A,{groupId:"split_dataset",children:(0,i.jsx)(l.default,{value:"python",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",metastring:'title="split_dataset"',children:'from lastmile.lib.auto_eval import AutoEval, Metric\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\n\nclient = AutoEval(api_token="api_token_if_LASTMILE_API_TOKEN_not_set")\ndataset_df = client.download_dataset(dataset_id=dataset_id) # Labeled dataset from previous step\n\n# Split the data into training and test sets\ntrain_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n\ntrain_df.to_csv(\'train.csv\', index=False)\ntest_df.to_csv(\'test.csv\', index=False)\n\ntest_dataset_id = client.upload_dataset(\n  file_path="test.csv",  # Your test dataset file\n  name="My Test Dataset for Fine-tuning",\n  description="Test dataset for evaluating the fine-tuned model"\n)\n\ntrain_dataset_id = client.upload_dataset(\n  file_path="train.csv",\n  name="My Training Dataset for Fine-tuning",\n  description="Training dataset for the fine-tuned model"\n)\n'})})})}),"\n",(0,i.jsx)(n.h3,{id:"fine-tune-model",children:"Fine-tune model"}),"\n",(0,i.jsx)(n.p,{children:"At this point we have labeled application data to train, and test the model. Time to fine-tune!"}),"\n",(0,i.jsx)(n.h4,{id:"api",children:"API"}),"\n",(0,i.jsxs)(s.A,{groupId:"fine_tune",children:[(0,i.jsx)(l.default,{value:"python",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",metastring:'title="fine_tune"',children:'# Continuation from previous step\nfine_tune_job_id = client.fine_tune_model(\n  train_dataset_id=train_dataset_id,  \n  test_dataset_id=test_dataset_id,\n  model_name="My Custom Evaluation Metric",\n  selected_columns=["input", "output", "ground_truth"], # You can decide which of these columns to include in the training data\n  wait_for_completion=False # Set to true for blocking\n)\n\nprint(f"Fine-tuning job initiated with ID: {fine_tune_job_id}. Waiting for completion...")\nclient.wait_for_fine_tune_job(fine_tune_job_id)\nprint(f"Fine-tuning job completed with ID: {fine_tune_job_id}")\n'})})}),(0,i.jsx)(l.default,{value:"node.js",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",metastring:'title="fine_tune"',children:'import { AutoEval } from "lastmile/lib/auto_eval";\nconst client = new AutoEval({\n  apiKey: "api_token_if_LASTMILE_API_TOKEN_not_set",\n});\nconst modelName = "My Custom Evaluation Metric";\nconst fineTuningJobId = await client.fineTuneModel({\n  trainDatasetId: datasetId,\n  modelName,\n  selectedColumns: ["input", "output", "ground_truth"],\n  waitForCompletion: false, // Set to  true to block until completion\n});\n\nconsole.log(`Fine-tuning job initiated with ID: ${fineTuningJobId}. Waiting for completion...`);\nawait client.waitForFineTuneJob(fineTuningJobId);\nconsole.log(`Fine-tuning job completed with ID: ${fineTuningJobId}`);\n'})})})]}),"\n",(0,i.jsx)(n.h4,{id:"ui",children:"UI"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Navigate to ",(0,i.jsx)(n.a,{href:"https://lastmileai.dev/models",children:"Model Console"})," and click ",(0,i.jsx)(n.strong,{children:"Fine-Tune a Model"}),".\n",(0,i.jsx)(n.img,{alt:"Model Console",src:t(85345).A+"",width:"2652",height:"1766"})]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Fill out the Fine-tuning form and click Submit to start the training job.\n",(0,i.jsx)(n.img,{alt:"Fine-tuning Wizard",src:t(1759).A+"",width:"2682",height:"2240"})]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Track progress in the ",(0,i.jsx)(n.a,{href:"https://lastmileai.dev/models",children:"Model Console"}),", including training metrics such as loss/accuracy."]}),"\n",(0,i.jsx)(n.admonition,{type:"info",children:(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"#weights--biases-integration",children:"Set up"})," your Weights & Biases API key to have the training data logged to your own W&B account if you prefer."]})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Fine-tuning Sneak Peek",src:t(29369).A+"",width:"2664",height:"1758"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"use-fine-tuned-model",children:"Use fine-tuned model"}),"\n",(0,i.jsxs)(n.p,{children:["Once the model is trained and deployed on the inference server, it will be listed as \ud83d\udfe2 ",(0,i.jsx)(n.strong,{children:"Online"})," in the dashboard."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Fine-tuned Model Details",src:t(69305).A+"",width:"2684",height:"1146"})}),"\n",(0,i.jsxs)(n.p,{children:["You can try it out directly in the playground, and see its training metrics in the ",(0,i.jsx)(n.strong,{children:"Fine-Tune Info"})," tab."]}),"\n",(0,i.jsx)(n.h4,{id:"api-1",children:"API"}),"\n",(0,i.jsx)(n.p,{children:"Use the API to run evals using your new model"}),"\n",(0,i.jsxs)(s.A,{groupId:"run_inference",children:[(0,i.jsx)(l.default,{value:"python",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",metastring:'title="run_inference"',children:'\nfine_tuned_metric = Metric(name="My Custom Evaluation Metric") # Reference the fine-tuned model by name or id\n\n# Run evals on your test/holdout dataset to see how the model is performing\ntest_results_df = client.evaluate_dataset(test_dataset_id, fine_tuned_metric)\n\n# Run evals on any application data\neval_results_df = client.evaluate_data(\n  # data should include the columns that the model expects\n  data=pd.DataFrame({\n      "input": ["What is the meaning of life?"],\n      "output": ["42"],\n      "ground_truth": ["Life, universe and everything"]\n  }),\n  metrics=[fine_tuned_metric],\n)\n'})})}),(0,i.jsx)(l.default,{value:"node.js",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",metastring:'title="run_inference"',children:'import { AutoEval, Metric } from "lastmile/lib/auto_eval";\nconst client = new AutoEval({\n  apiKey: "api_token_if_LASTMILE_API_TOKEN_not_set",\n});\n\nconst metric: Metric = {\n  name: "My Custom Evaluation Metric",\n};\n\nconsole.log(`Waiting for fine-tuned model \'${metric.name}\' to be available as a metric...`);\nconst fineTunedMetric = await client.waitForMetricOnline(metric);\nconsole.log(`Fine-tuned model \'${metric.name}\' is now available as a metric with ID: ${fineTunedMetric.id}.`);\n\n// Run evals on your test/holdout dataset to see how the model is performing\nconst testResults = await client.evaluateDataset(testDatasetId, fineTunedMetric);\nconsole.table(testResults);\n\n// Run evals on any application data\nconst results = await client.evaluateData(\n  /*data*/ [\n    {\n      "input": "What is the meaning of life?",\n      "output": "42",\n      "ground_truth": "Life, universe and everything"\n    }\n  ],\n  /*metrics*/ [fineTunedMetric]\n);\nconsole.table(results);\n'})})})]}),"\n",(0,i.jsx)(n.h3,{id:"weights--biases-integration",children:"Weights & Biases integration"}),"\n",(0,i.jsxs)(n.p,{children:["AutoEval allows you to track detailed training runs in your own Weights & Biases account. To do so, navigate to the ",(0,i.jsx)(n.a,{href:"https://lastmileai.dev/apikeys",children:"API Keys console"}),", and save your W&B API key.\nSubsequent fine-tuning runs will be tracked in your account.\n",(0,i.jsx)(n.img,{alt:"Wandb Integration",src:t(12782).A+"",width:"2692",height:"1758"})]})]})}function m(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}},79402:(e,n,t)=>{var i=t(38193);!!i.default.canUseDOM&&navigator.platform.startsWith("Mac"),!!i.default.canUseDOM&&navigator.platform.startsWith("Win")},4865:(e,n,t)=>{t.d(n,{A:()=>m});var i=t(96540),a=t(18215),s=t(23104),l=t(47751),o=t(92303);const r={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var d=t(74848);function c(e){let{className:n,block:t,selectedValue:i,selectValue:l,tabValues:o}=e;const c=[],{blockElementScrollPositionUntilNextRender:u}=(0,s.a_)(),h=e=>{const n=e.currentTarget,t=c.indexOf(n),a=o[t].value;a!==i&&(u(n),l(a))},m=e=>{let n=null;switch(e.key){case"Enter":h(e);break;case"ArrowRight":{const t=c.indexOf(e.currentTarget)+1;n=c[t]??c[0];break}case"ArrowLeft":{const t=c.indexOf(e.currentTarget)-1;n=c[t]??c[c.length-1];break}}n?.focus()};return(0,d.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,a.A)("tabs",{"tabs--block":t},n),children:o.map((e=>{let{value:n,label:t,attributes:s}=e;return(0,d.jsx)("li",{role:"tab",tabIndex:i===n?0:-1,"aria-selected":i===n,ref:e=>c.push(e),onKeyDown:m,onClick:h,...s,className:(0,a.A)("tabs__item",r.tabItem,s?.className,{"tabs__item--active":i===n}),children:t??n},n)}))})}function u(e){let{lazy:n,children:t,selectedValue:s}=e;const l=(Array.isArray(t)?t:[t]).filter(Boolean);if(n){const e=l.find((e=>e.props.value===s));return e?(0,i.cloneElement)(e,{className:(0,a.A)("margin-top--md",e.props.className)}):null}return(0,d.jsx)("div",{className:"margin-top--md",children:l.map(((e,n)=>(0,i.cloneElement)(e,{key:n,hidden:e.props.value!==s})))})}function h(e){const n=(0,l.u)(e);return(0,d.jsxs)("div",{className:(0,a.A)("tabs-container",r.tabList),children:[(0,d.jsx)(c,{...n,...e}),(0,d.jsx)(u,{...n,...e})]})}function m(e){const n=(0,o.default)();return(0,d.jsx)(h,{...e,children:(0,l.v)(e.children)},String(n))}},12782:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/wandb-fb16c9d82c3bcad654ae765634a8ba6d.png"},59413:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/autoeval_flow_finetuning-9b3921aa3bd1792c90a78620611f1b2b.png"},1759:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/fine_tuning_form-9f92260f5605064dd07d783d3ba93aec.png"},69305:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/fine_tuning_model_details-af5f7d2845af8f61e6df6a9d76f7de22.png"},29369:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/fine_tuning_progress_data-3b268d1344a133cd0792d5f2628585f9.png"},85345:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/model_console-85d995cf9d39d490b4b5c1308f19bb1f.png"}}]);