/*! For license information please see 18891827.ee11aca2.js.LICENSE.txt */
(self.webpackChunklastmile_docs=self.webpackChunklastmile_docs||[]).push([[1235],{35434:(e,t,a)=>{"use strict";a.r(t),a.d(t,{assets:()=>x,contentTitle:()=>g,default:()=>y,frontMatter:()=>f,metadata:()=>v,toc:()=>b});var i=a(74848),n=a(28453),s=a(4865),r=a(19365),l=(a(79402),a(47938)),o=a(63821),c=(a(96540),a(46942)),u=a.n(c);const d={splitPane:"splitPane_bO8i",leftPane:"leftPane_de69",rightPane:"rightPane_Z18N",icon:"icon_QiKa"};function m(e){let{leftChild:t,rightChild:a,className:n,leftPaneClassName:s,rightPaneClassName:r}=e;return(0,i.jsxs)("div",{className:u()(d.splitPane,n),children:[(0,i.jsx)("div",{className:u()(d.leftPane,s),children:t}),(0,i.jsx)("div",{className:u()(d.rightPane,r),children:a})]})}var h=a(52138);function p(e){let{codeBlocks:t,defaultLanguage:a}=e;return(0,i.jsx)(m,{className:"getting-started-card",leftPaneClassName:"getting-started-card-left-pane",rightPaneClassName:"getting-started-card-right-pane",leftChild:(0,i.jsxs)("a",{href:"/quickstart",children:[(0,i.jsx)("h3",{children:"Developer quickstart"}),(0,i.jsx)("p",{children:"Compute your first evaluation metric within 5 minutes."})]}),rightChild:(0,i.jsx)(s.A,{children:t.map((e=>{let{language:t,label:n,code:s}=e;return(0,i.jsx)(r.default,{value:n??t,label:n??t,default:a===t,children:(0,i.jsx)(h.default,{language:t,children:s})},n??t)}))})})}const f={id:"overview",slug:"/"},g="Introduction",v={id:"overview",title:"Introduction",description:"LastMile is the full-stack developer platform to debug, evaluate and improve LLM applications. We make it easy to fine-tune custom evaluators, set up guardrails & monitor app performance.",source:"@site/docs/overview.mdx",sourceDirName:".",slug:"/",permalink:"/",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{id:"overview",slug:"/"},sidebar:"sidebar",next:{title:"Quickstart",permalink:"/quickstart"}},x={},b=[{value:"Design your own metric",id:"design-your-own-metric",level:2},{value:"Out-of-the-box metrics",id:"out-of-the-box-metrics",level:2},{value:"Meet alBERTa \ud83c\udf41",id:"meet-alberta-",level:2},{value:"Explore our guides",id:"explore-our-guides",level:2}];function j(e){const t={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,n.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.header,{children:(0,i.jsx)(t.h1,{id:"introduction",children:"Introduction"})}),"\n",(0,i.jsxs)(t.p,{children:["LastMile is the ",(0,i.jsx)(t.a,{href:"/autoeval",children:"full-stack developer platform"})," to debug, evaluate and ",(0,i.jsx)("u",{children:"improve"})," LLM applications. We make it easy to fine-tune custom evaluators, set up guardrails & monitor app performance."]}),"\n",(0,i.jsx)(p,{defaultLanguage:"python",codeBlocks:[{language:"python",code:'from lastmile.lib.auto_eval import AutoEval, Metric\nimport pandas as pd\n\nresult = AutoEval().evaluate_data(\n  data=pd.DataFrame({\n      "input": ["Where did the author grow up?"],\n      "output": ["France"],\n      "ground_truth": ["England"]\n  }),\n  metrics=[Metric(name="Faithfulness")]\n)\n\nprint(f\'Evlauation result:\', result)'},{language:"javascript",label:"node.js",code:'import {Lastmile, Metric} from \'lastmile\';\n\nconst client = new Lastmile();\n\nconst response = await client.evaluation.evaluate({\n  input: ["Where did the author grow up?"],\n  output: ["France"],\n  groundTruth: ["England"]\n  metric: Metric(name: "Faithfulness")\n});\n'}]}),"\n",(0,i.jsx)(t.h2,{id:"design-your-own-metric",children:"Design your own metric"}),"\n",(0,i.jsx)(t.p,{children:"Use the fine-tuning service to design your own evaluators that represent custom criteria for your app quality."}),"\n",(0,i.jsxs)(o.x,{className:"custom-grid customize",children:[(0,i.jsx)(l.Z,{href:"/autoeval/datasets",title:"1. Create Datasets",description:"Upload and manage application data for running and training evals, and generate synthetic labels.",className:"custom-card datasets"}),(0,i.jsx)(l.Z,{href:"/autoeval/labeling",title:"2. LLM Judge++",description:"Generate high-quality labels for your data using LLM Judge with human-in-the-loop active learning",className:"custom-card labeling"}),(0,i.jsx)(l.Z,{href:"/autoeval/fine-tune",title:"3. Fine-tune Evaluators",description:"Use the AutoEval fine-tuning service to develop custom metrics for your application.",className:"custom-card fine-tune"}),(0,i.jsx)(l.Z,{href:"/autoeval/models#usage-guide",title:"4. Run Evals",description:"Compute metrics by running high-performance inference using a prebuilt or fine-tuned model.",className:"custom-card models"})]}),"\n",(0,i.jsx)(t.h2,{id:"out-of-the-box-metrics",children:"Out-of-the-box metrics"}),"\n",(0,i.jsx)(t.p,{children:"Batteries-included evaluation metrics covering common AI application types, such as RAG and multi-agent compound AI systems."}),"\n",(0,i.jsxs)(o.x,{className:"custom-grid",children:[(0,i.jsx)(l.Z,{href:"/autoeval/metrics",title:"Faithfulness",description:"Measures how adherent or faithful an LLM response is to the provided context. Often used for hallucination detection.",className:"custom-card faithfulness"}),(0,i.jsx)(l.Z,{href:"/autoeval/metrics",title:"Semantic Similarity",description:"Measures semantic similarity between two strings. Often used for context relevance, or input/output relevance, or similarity between a response and ground truth.",className:"custom-card similarity"}),(0,i.jsx)(l.Z,{href:"/autoeval/metrics",title:"Summarization Quality",description:"Quantify the quality of a summarization response.",className:"custom-card summarization"}),(0,i.jsx)(l.Z,{href:"/autoeval/metrics",title:"Toxicity",description:"Quantify the toxicity level in an LLM response.",className:"custom-card toxicity"}),(0,i.jsx)(l.Z,{href:"/autoeval/metrics",title:"More",description:"Explore other metrics available in AutoEval, or keep reading to design your own metric.",className:"custom-card"})]}),"\n",(0,i.jsx)(t.h2,{id:"meet-alberta-",children:"Meet alBERTa \ud83c\udf41"}),"\n",(0,i.jsx)(t.p,{children:"alBERTa is a family of small language models (SLMs) designed for evaluation. They are optimized to be:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"small"})," -- 400M parameter entailment model"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"fast"})," -- can run inference on CPU in < 300ms"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"customizable"})," -- fine-tune for custom evaluation tasks"]}),"\n"]}),"\n",(0,i.jsxs)(o.x,{className:"alberta-grid",children:[(0,i.jsx)(l.Z,{href:"/autoeval/models#usage-guide",title:"alBERTa-512 \ud83c\udf41",description:"512 token context, specialized for evaluation tasks (like faithfulness), and gives a numeric 0->1 score.",backgroundColor:"#F5F5F5",className:"custom-card model-512"}),(0,i.jsx)(l.Z,{href:"/autoeval/models#usage-guide",title:"alBERTa-LC-8k \ud83c\udf41",description:"Long-context window variant that can scale to 128k+ tokens using a scaled dot-product attention layer",backgroundColor:"#F5F5F5",className:"custom-card model-8k"})]}),"\n",(0,i.jsx)(t.h2,{id:"explore-our-guides",children:"Explore our guides"}),"\n",(0,i.jsxs)(o.x,{className:"guides-grid",children:[(0,i.jsx)(l.Z,{href:"https://github.com/lastmile-ai/lastmile-docs/blob/main/cookbook/AutoEval_Getting_Started.ipynb",title:"Quickstart",description:"Start-to-finish overview of AutoEval, from running evals, labeling with LLM Judge to fine-tuning a custom metric.",className:"custom-card"}),(0,i.jsx)(l.Z,{href:"https://github.com/lastmile-ai/lastmile-docs/blob/main/cookbook/RAG_Evaluation.ipynb",title:"Retrieval systems",description:"Evaluate a RAG application for hallucination, relevance and other out-of-the-box metrics available via AutoEval.",className:"custom-card"}),(0,i.jsx)(l.Z,{href:"https://github.com/lastmile-ai/lastmile-docs/blob/main/cookbook/RAG_Guardrails.ipynb",title:"Real-time guardrails",description:"Build real-time guardrails in a RAG application using fine-tuned alBERTa \ud83c\udf41 models.",className:"custom-card"})]})]})}function y(e={}){const{wrapper:t}={...(0,n.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(j,{...e})}):j(e)}},79402:(e,t,a)=>{"use strict";var i=a(38193);!!i.default.canUseDOM&&navigator.platform.startsWith("Mac"),!!i.default.canUseDOM&&navigator.platform.startsWith("Win")},4865:(e,t,a)=>{"use strict";a.d(t,{A:()=>h});var i=a(96540),n=a(18215),s=a(23104),r=a(47751),l=a(92303);const o={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var c=a(74848);function u(e){let{className:t,block:a,selectedValue:i,selectValue:r,tabValues:l}=e;const u=[],{blockElementScrollPositionUntilNextRender:d}=(0,s.a_)(),m=e=>{const t=e.currentTarget,a=u.indexOf(t),n=l[a].value;n!==i&&(d(t),r(n))},h=e=>{let t=null;switch(e.key){case"Enter":m(e);break;case"ArrowRight":{const a=u.indexOf(e.currentTarget)+1;t=u[a]??u[0];break}case"ArrowLeft":{const a=u.indexOf(e.currentTarget)-1;t=u[a]??u[u.length-1];break}}t?.focus()};return(0,c.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,n.A)("tabs",{"tabs--block":a},t),children:l.map((e=>{let{value:t,label:a,attributes:s}=e;return(0,c.jsx)("li",{role:"tab",tabIndex:i===t?0:-1,"aria-selected":i===t,ref:e=>u.push(e),onKeyDown:h,onClick:m,...s,className:(0,n.A)("tabs__item",o.tabItem,s?.className,{"tabs__item--active":i===t}),children:a??t},t)}))})}function d(e){let{lazy:t,children:a,selectedValue:s}=e;const r=(Array.isArray(a)?a:[a]).filter(Boolean);if(t){const e=r.find((e=>e.props.value===s));return e?(0,i.cloneElement)(e,{className:(0,n.A)("margin-top--md",e.props.className)}):null}return(0,c.jsx)("div",{className:"margin-top--md",children:r.map(((e,t)=>(0,i.cloneElement)(e,{key:t,hidden:e.props.value!==s})))})}function m(e){const t=(0,r.u)(e);return(0,c.jsxs)("div",{className:(0,n.A)("tabs-container",o.tabList),children:[(0,c.jsx)(u,{...t,...e}),(0,c.jsx)(d,{...t,...e})]})}function h(e){const t=(0,l.default)();return(0,c.jsx)(m,{...e,children:(0,r.v)(e.children)},String(t))}},47938:(e,t,a)=>{"use strict";a.d(t,{Z:()=>l});a(96540);var i=a(46942),n=a.n(i);const s={card:"card_kyB9",cardTitle:"cardTitle_WmU7",icon:"icon_xMNd"};var r=a(74848);function l(e){let{href:t,title:a,description:i,className:l}=e;return(0,r.jsxs)("a",{href:t,className:n()(s.card,l),children:[(0,r.jsxs)("h3",{className:s.cardTitle,children:[a,(0,r.jsx)("span",{className:s.icon,children:">"})]}),(0,r.jsx)("p",{children:i})]})}},63821:(e,t,a)=>{"use strict";a.d(t,{x:()=>l});a(96540);var i=a(46942),n=a.n(i);const s={grid:"grid_qyhz"};var r=a(74848);function l(e){let{children:t,className:a}=e;return(0,r.jsx)("div",{className:n()(s.grid,a),children:t})}},46942:(e,t)=>{var a;!function(){"use strict";var i={}.hasOwnProperty;function n(){for(var e="",t=0;t<arguments.length;t++){var a=arguments[t];a&&(e=r(e,s(a)))}return e}function s(e){if("string"==typeof e||"number"==typeof e)return e;if("object"!=typeof e)return"";if(Array.isArray(e))return n.apply(null,e);if(e.toString!==Object.prototype.toString&&!e.toString.toString().includes("[native code]"))return e.toString();var t="";for(var a in e)i.call(e,a)&&e[a]&&(t=r(t,a));return t}function r(e,t){return t?e?e+" "+t:e+t:e}e.exports?(n.default=n,e.exports=n):void 0===(a=function(){return n}.apply(t,[]))||(e.exports=a)}()}}]);