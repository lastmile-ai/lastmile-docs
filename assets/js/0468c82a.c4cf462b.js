"use strict";(self.webpackChunklastmile_docs=self.webpackChunklastmile_docs||[]).push([[8323],{15361:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>o,contentTitle:()=>r,default:()=>d,frontMatter:()=>l,metadata:()=>s,toc:()=>c});var n=t(74848),i=t(28453);t(4865),t(19365),t(79402);const l={title:"AutoEval Developer Platform"},r="AutoEval",s={id:"autoeval/index",title:"AutoEval Developer Platform",description:"Platform Overview",source:"@site/docs/autoeval/index.mdx",sourceDirName:"autoeval",slug:"/autoeval/",permalink:"/autoeval/",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{title:"AutoEval Developer Platform"},sidebar:"sidebar",previous:{title:"Quickstart",permalink:"/quickstart"},next:{title:"Introduction",permalink:"/autoeval/autoeval-intro"}},o={},c=[{value:"Platform Capabilities",id:"platform-capabilities",level:2},{value:"Out-of-the-box metrics",id:"out-of-the-box-metrics",level:3},{value:"Dataset Management",id:"dataset-management",level:3},{value:"Synthetic Labeling (LLM Judge Labeling)",id:"synthetic-labeling-llm-judge-labeling",level:3},{value:"Fine-tuning",id:"fine-tuning",level:3},{value:"Online inference",id:"online-inference",level:3}];function u(e){const a={a:"a",admonition:"admonition",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(a.header,{children:(0,n.jsx)(a.h1,{id:"autoeval",children:"AutoEval"})}),"\n",(0,n.jsx)(a.p,{children:"Platform Overview"}),"\n",(0,n.jsxs)(a.p,{children:["The AutoEval fine-tuning platform enables the customization of ",(0,n.jsx)(a.a,{href:"/autoeval/models",children:"alBERTa small language models"})," (SLMs) to better evaluate and measure your application's performance."]}),"\n",(0,n.jsx)(a.p,{children:"It solves a key problem in generative AI application development -- helping you develop metrics that accurately represent your application's performance, enabling you to\niteratively drive improvements and have confidence in production."}),"\n",(0,n.jsx)(a.p,{children:"Here's how it works:"}),"\n",(0,n.jsx)(a.p,{children:(0,n.jsx)(a.img,{alt:"autoeval-flow",src:t(44765).A+"",width:"4608",height:"1184"})}),"\n",(0,n.jsx)(a.p,{children:"You come to AutoEval if you have a compound AI application, such as a RAG pipeline or agent system, and you want to understand if the application is performing well or not.\nThis can be a single quality metric of AI interactions, or a whole suite of metrics - each measuring something specific about the system:"}),"\n",(0,n.jsxs)(a.ul,{children:["\n",(0,n.jsx)(a.li,{children:(0,n.jsx)(a.em,{children:"Is the response faithful to the data provided?"})}),"\n",(0,n.jsx)(a.li,{children:(0,n.jsx)(a.em,{children:"Is the input relevant to the application's purpose? (input guardrail)"})}),"\n",(0,n.jsx)(a.li,{children:(0,n.jsx)(a.em,{children:"Does the response adhere to my company's brand tone?"})}),"\n"]}),"\n",(0,n.jsxs)(a.p,{children:["AutoEval starts from the application's trace ",(0,n.jsx)(a.a,{href:"/autoeval/datasets",children:"datasets"}),", ",(0,n.jsx)(a.a,{href:"/autoeval/labeling",children:"labels"})," the interactions using LLM Judge where you can specify an evaluation criteria in natural language (prompt),\nand then ",(0,n.jsx)(a.a,{href:"/autoeval/fine-tune",children:"fine-tunes"})," an alBERTa SLM to learn the distribution of those labeled interactions. You can then ",(0,n.jsx)(a.a,{href:"/autoeval/models#usage-guide",children:"run the fine-tuned model"}),"\nas an eval, or at runtime as a ",(0,n.jsx)(a.a,{href:"/autoeval/guardrails",children:"guardrail"}),". For e.g. if a response is deemed to have hallucinated, i.e. unsufficiently faithful to the data, then deny that response from reaching the user."]}),"\n",(0,n.jsx)(a.h2,{id:"platform-capabilities",children:"Platform Capabilities"}),"\n",(0,n.jsx)(a.p,{children:(0,n.jsx)(a.img,{src:"https://andrew-dev-s3.s3.amazonaws.com/autoeval-platform.png",alt:"autoeval-platform"})}),"\n",(0,n.jsx)(a.h3,{id:"out-of-the-box-metrics",children:"Out-of-the-box metrics"}),"\n",(0,n.jsxs)(a.p,{children:["Key metrics to evaluate typical AI applications (such as RAG) are available out of the box. Detect hallucinations, measure input/context relevance, score summarizations and more.\n",(0,n.jsx)(a.a,{href:"/autoeval/metrics",children:"Learn more"})]}),"\n",(0,n.jsx)(a.h3,{id:"dataset-management",children:"Dataset Management"}),"\n",(0,n.jsxs)(a.p,{children:["Store application trace data in AutoEval to be used for running evals, for labeling, and for fine-tuning evaluator models.\n",(0,n.jsx)(a.a,{href:"/autoeval/datasets",children:"Learn more"})]}),"\n",(0,n.jsx)(a.h3,{id:"synthetic-labeling-llm-judge-labeling",children:"Synthetic Labeling (LLM Judge Labeling)"}),"\n",(0,n.jsxs)(a.p,{children:["For use cases that have few to no labels or ground truth data, AutoEval provides the capability to synthetically generate labels.\nWe refer to this as ",(0,n.jsx)(a.strong,{children:"Synthetic Labeling"}),". It uses an LLM to generate labels given a custom evaluation criteria, and also allows a\ndeveloper to improve the labels manually as part of an refinement process (typically labeled by a subject matter expert)."]}),"\n",(0,n.jsx)(a.p,{children:"You can continuously improve the label quality by providing additional samples of ground truth data."}),"\n",(0,n.jsx)(a.p,{children:(0,n.jsx)(a.a,{href:"/autoeval/labeling",children:"Learn more"})}),"\n",(0,n.jsx)(a.h3,{id:"fine-tuning",children:"Fine-tuning"}),"\n",(0,n.jsxs)(a.p,{children:[(0,n.jsx)(a.strong,{children:"Design your own eval metric"}),". Fine-tuning allows you to improve the performance of LastMile AI's models by tuning the performance to your specific data and use case."]}),"\n",(0,n.jsx)(a.p,{children:(0,n.jsx)(a.a,{href:"/autoeval/fine-tune",children:"Learn more"})}),"\n",(0,n.jsx)(a.h3,{id:"online-inference",children:"Online inference"}),"\n",(0,n.jsxs)(a.p,{children:["You can use the evaluator models for offline tasks such as ",(0,n.jsx)(a.a,{href:"/autoeval/models#usage-guide",children:"running evals"}),", as well as online tasks such as ",(0,n.jsx)(a.a,{href:"/autoeval/guardrails",children:"guardrails"}),".\nAutoEval has a high-performance inference server that can handle both kinds of workloads."]}),"\n",(0,n.jsx)(a.admonition,{type:"info",children:(0,n.jsxs)(a.p,{children:["Use the ",(0,n.jsx)(a.a,{href:"/quickstart",children:"quickstart"})," guide to get started running your first evaluation."]})})]})}function d(e={}){const{wrapper:a}={...(0,i.R)(),...e.components};return a?(0,n.jsx)(a,{...e,children:(0,n.jsx)(u,{...e})}):u(e)}},79402:(e,a,t)=>{var n=t(38193);!!n.default.canUseDOM&&navigator.platform.startsWith("Mac"),!!n.default.canUseDOM&&navigator.platform.startsWith("Win")},4865:(e,a,t)=>{t.d(a,{A:()=>m});var n=t(96540),i=t(18215),l=t(23104),r=t(47751),s=t(92303);const o={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var c=t(74848);function u(e){let{className:a,block:t,selectedValue:n,selectValue:r,tabValues:s}=e;const u=[],{blockElementScrollPositionUntilNextRender:d}=(0,l.a_)(),h=e=>{const a=e.currentTarget,t=u.indexOf(a),i=s[t].value;i!==n&&(d(a),r(i))},m=e=>{let a=null;switch(e.key){case"Enter":h(e);break;case"ArrowRight":{const t=u.indexOf(e.currentTarget)+1;a=u[t]??u[0];break}case"ArrowLeft":{const t=u.indexOf(e.currentTarget)-1;a=u[t]??u[u.length-1];break}}a?.focus()};return(0,c.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,i.A)("tabs",{"tabs--block":t},a),children:s.map((e=>{let{value:a,label:t,attributes:l}=e;return(0,c.jsx)("li",{role:"tab",tabIndex:n===a?0:-1,"aria-selected":n===a,ref:e=>u.push(e),onKeyDown:m,onClick:h,...l,className:(0,i.A)("tabs__item",o.tabItem,l?.className,{"tabs__item--active":n===a}),children:t??a},a)}))})}function d(e){let{lazy:a,children:t,selectedValue:l}=e;const r=(Array.isArray(t)?t:[t]).filter(Boolean);if(a){const e=r.find((e=>e.props.value===l));return e?(0,n.cloneElement)(e,{className:(0,i.A)("margin-top--md",e.props.className)}):null}return(0,c.jsx)("div",{className:"margin-top--md",children:r.map(((e,a)=>(0,n.cloneElement)(e,{key:a,hidden:e.props.value!==l})))})}function h(e){const a=(0,r.u)(e);return(0,c.jsxs)("div",{className:(0,i.A)("tabs-container",o.tabList),children:[(0,c.jsx)(u,{...a,...e}),(0,c.jsx)(d,{...a,...e})]})}function m(e){const a=(0,s.default)();return(0,c.jsx)(h,{...e,children:(0,r.v)(e.children)},String(a))}},44765:(e,a,t)=>{t.d(a,{A:()=>n});const n=t.p+"assets/images/autoeval_flow-e7392950d668ae4563466c42bda97c04.png"}}]);