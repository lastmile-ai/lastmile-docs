"use strict";(self.webpackChunklastmile_docs=self.webpackChunklastmile_docs||[]).push([[1567],{55226:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"sidebar":[{"type":"link","label":"LastMile AI","href":"/","docId":"intro","unlisted":false},{"type":"link","label":"Evaluation and Guardrails Overview","href":"/overview","docId":"overview","unlisted":false},{"type":"link","label":"Quickstart","href":"/quickstart","docId":"quickstart","unlisted":false},{"type":"category","label":"Models","items":[{"type":"link","label":"AlBERTa","href":"/alberta","docId":"alberta","unlisted":false},{"type":"link","label":"AlBERTa-LC-8k","href":"/alberta-8k","docId":"alberta-8k","unlisted":false}],"collapsible":true,"collapsed":false,"href":"/models"},{"type":"category","label":"AutoEval Platform","items":[{"type":"link","label":"Synthetic Data Generation","href":"/data-generation","docId":"data-generation","unlisted":false},{"type":"link","label":"Fine-tuning AlBERTa","href":"/fine-tuning","docId":"fine-tuning","unlisted":false},{"type":"link","label":"Active Learning","href":"/active-learning","docId":"active-learning","unlisted":false}],"collapsible":true,"collapsed":false,"href":"/platform"},{"type":"link","label":"Metrics Overview","href":"/metrics","docId":"metrics","unlisted":false},{"type":"link","label":"Deployment Options","href":"/deployment","docId":"deployment","unlisted":false},{"type":"link","label":"Cookbook","href":"https://github.com/lastmile-ai/eval-cookbook"},{"type":"link","label":"AutoEval Python SDK","href":"/sdk","docId":"sdk","unlisted":false},{"type":"link","label":"AI Workbooks","href":"/workbooks","docId":"workbooks","unlisted":false},{"type":"link","label":"AIConfig","href":"https://aiconfig.lastmileai.dev/docs/basics"},{"type":"category","label":"API Specs","items":[{"type":"link","label":"Introduction","href":"/api/lastmile-ai-api-v-2","docId":"api/lastmile-ai-api-v-2","unlisted":false},{"type":"category","label":"Model Fine Tune Worker Service","items":[{"type":"link","label":"Execute Fine Tune Job","href":"/api/execute-fine-tune-job","className":"api-method post","docId":"api/execute-fine-tune-job","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Model Service","items":[{"type":"link","label":"List Metric Bases","href":"/api/list-metric-base-models","className":"api-method post","docId":"api/list-metric-base-models","unlisted":false},{"type":"link","label":"Get Card","href":"/api/get-model-card","className":"api-method post","docId":"api/get-model-card","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Dataset Service","items":[{"type":"link","label":"Create File","href":"/api/create-dataset-file","className":"api-method post","docId":"api/create-dataset-file","unlisted":false},{"type":"link","label":"Check Accessibility","href":"/api/check-dataset-accessibility","className":"api-method post","docId":"api/check-dataset-accessibility","unlisted":false},{"type":"link","label":"Introspect","href":"/api/introspect-dataset","className":"api-method post","docId":"api/introspect-dataset","unlisted":false},{"type":"link","label":"Collect Metadata","href":"/api/collect-dataset-metadata","className":"api-method put","docId":"api/collect-dataset-metadata","unlisted":false},{"type":"link","label":"View","href":"/api/view-dataset","className":"api-method post","docId":"api/view-dataset","unlisted":false},{"type":"link","label":"Define Splits","href":"/api/define-dataset-splits","className":"api-method put","docId":"api/define-dataset-splits","unlisted":false},{"type":"link","label":"Create Pseudo Label Job","href":"/api/create-pseudo-label-job","className":"api-method post","docId":"api/create-pseudo-label-job","unlisted":false},{"type":"link","label":"Refine Labels","href":"/api/refine-labels","className":"api-method post","docId":"api/refine-labels","unlisted":false},{"type":"link","label":"Augment","href":"/api/augment-dataset","className":"api-method post","docId":"api/augment-dataset","unlisted":false},{"type":"link","label":"Refine Augmented Rows","href":"/api/refine-augmented-rows","className":"api-method post","docId":"api/refine-augmented-rows","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Fine Tune Service","items":[{"type":"link","label":"Create Job","href":"/api/create-fine-tune-job","className":"api-method post","docId":"api/create-fine-tune-job","unlisted":false},{"type":"link","label":"Configure Hyper Parameters","href":"/api/configure-hyper-parameters","className":"api-method put","docId":"api/configure-hyper-parameters","unlisted":false},{"type":"link","label":"Run Job","href":"/api/run-fine-tune-job","className":"api-method post","docId":"api/run-fine-tune-job","unlisted":false},{"type":"link","label":"Get Job Status","href":"/api/get-job-status","className":"api-method post","docId":"api/get-job-status","unlisted":false},{"type":"link","label":"View Results","href":"/api/view-fine-tune-results","className":"api-method post","docId":"api/view-fine-tune-results","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Deployment Service","items":[{"type":"link","label":"Deploy Inference Endpoint","href":"/api/deploy-inference-endpoint","className":"api-method post","docId":"api/deploy-inference-endpoint","unlisted":false},{"type":"link","label":"Create Docker Image","href":"/api/create-docker-image","className":"api-method post","docId":"api/create-docker-image","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsible":true,"collapsed":true,"href":"/category/api-specs"}]},"docs":{"active-learning":{"id":"active-learning","title":"Active Learning","description":"Active learning is in which we use an algorithm (an LLM in this case) to interactively label the training data. You can continuously improve the active learning by providing additional samples of ground truth data.","sidebar":"sidebar"},"alberta":{"id":"alberta","title":"AlBERTa","description":"A 400M parameter state-of-the-art, encoder based model designed for evaluating. This models works well without few-shot prompting or fine-tuning. However, for further performance improvements, the AlBERTa fleet of models are available for fine-tuning.","sidebar":"sidebar"},"alberta-8k":{"id":"alberta-8k","title":"AlBERTa-LC-8k","description":"A 400M parameter state-of-the-art, encoder based model for calcuating the factual consistency of the generated answer against the provided context.","sidebar":"sidebar"},"api/augment-dataset":{"id":"api/augment-dataset","title":"Augment","description":"Description of augment","sidebar":"sidebar"},"api/check-dataset-accessibility":{"id":"api/check-dataset-accessibility","title":"Check Accessibility","description":"Description of checkAccessibility","sidebar":"sidebar"},"api/collect-dataset-metadata":{"id":"api/collect-dataset-metadata","title":"Collect Metadata","description":"Description of collectMetadata","sidebar":"sidebar"},"api/configure-hyper-parameters":{"id":"api/configure-hyper-parameters","title":"Configure Hyper Parameters","description":"Description of configureHyperParameters","sidebar":"sidebar"},"api/create-dataset-file":{"id":"api/create-dataset-file","title":"Create File","description":"Description of createFile","sidebar":"sidebar"},"api/create-docker-image":{"id":"api/create-docker-image","title":"Create Docker Image","description":"Description of createDockerImage","sidebar":"sidebar"},"api/create-fine-tune-job":{"id":"api/create-fine-tune-job","title":"Create Job","description":"Description of createJob","sidebar":"sidebar"},"api/create-pseudo-label-job":{"id":"api/create-pseudo-label-job","title":"Create Pseudo Label Job","description":"Description of createPseudoLabelJob","sidebar":"sidebar"},"api/define-dataset-splits":{"id":"api/define-dataset-splits","title":"Define Splits","description":"Description of defineSplits","sidebar":"sidebar"},"api/deploy-inference-endpoint":{"id":"api/deploy-inference-endpoint","title":"Deploy Inference Endpoint","description":"Description of deployInferenceEndpoint","sidebar":"sidebar"},"api/execute-fine-tune-job":{"id":"api/execute-fine-tune-job","title":"Execute Fine Tune Job","description":"Actually execute the fine-tune job","sidebar":"sidebar"},"api/get-job-status":{"id":"api/get-job-status","title":"Get Job Status","description":"Description of getJobStatus","sidebar":"sidebar"},"api/get-model-card":{"id":"api/get-model-card","title":"Get Card","description":"Description of getCard","sidebar":"sidebar"},"api/introspect-dataset":{"id":"api/introspect-dataset","title":"Introspect","description":"Description of introspect","sidebar":"sidebar"},"api/lastmile-ai-api-v-2":{"id":"api/lastmile-ai-api-v-2","title":"LastMile AI API V2","description":"LastMile AI API V2: Components","sidebar":"sidebar"},"api/list-metric-base-models":{"id":"api/list-metric-base-models","title":"List Metric Bases","description":"Description of listMetricBases","sidebar":"sidebar"},"api/refine-augmented-rows":{"id":"api/refine-augmented-rows","title":"Refine Augmented Rows","description":"Description of refineAugmentedRows","sidebar":"sidebar"},"api/refine-labels":{"id":"api/refine-labels","title":"Refine Labels","description":"Description of refineLabels","sidebar":"sidebar"},"api/run-fine-tune-job":{"id":"api/run-fine-tune-job","title":"Run Job","description":"Description of runJob","sidebar":"sidebar"},"api/view-dataset":{"id":"api/view-dataset","title":"View","description":"Description of view","sidebar":"sidebar"},"api/view-fine-tune-results":{"id":"api/view-fine-tune-results","title":"View Results","description":"Description of viewResults","sidebar":"sidebar"},"data-generation":{"id":"data-generation","title":"Synthetic Data Generation","description":"For use cases that have few to no labels or ground truth data, the AutoEval platform provides the capability to synthetically generate labels. Synthetic Data Generation involves using a model to create data that matches what a realistic response would be and matches the underlying distribution of the data. The platform does its initial labeling through a large-language model (LLM) and over time aligns the performance of the synthetic labels to the ground truth data.","sidebar":"sidebar"},"deployment":{"id":"deployment","title":"Deployment Options","description":"Hosted by LastMile AI","sidebar":"sidebar"},"fine-tuning":{"id":"fine-tuning","title":"Fine-tuning AlBERTa","description":"Fine-tuning allows you to improve the performance of LastMile AI\'s models by tuning the performance to your specific data and use case. Fine-tuning is the process of adapting the small language models for specific tasks. Example use cases from customers:","sidebar":"sidebar"},"intro":{"id":"intro","title":"LastMile AI","description":"LastMile AI enables developers and enterprises to confidentally test and evaluate their LLM-powered applications. We combine the best models with our world-class platform to","sidebar":"sidebar"},"metrics":{"id":"metrics","title":"Metrics Overview","description":"Evaluation Metrics are the key to unlocking development velocity and safety in productionizing LLM applications. Metrics measure the performance of your LLM (or Retrieval Augmented Generation - RAG) applications. LastMile AI\'s metrics include hallucination detection, summarization, relevance, q/a, semantic similarity, exact match, bleu, rouge, and toxicity.","sidebar":"sidebar"},"models":{"id":"models","title":"Models Overview","description":"LastMile AI provides small foundational models for evaluating your specific use case for your success metric. If you need additional customization, you can fine-tune these foundational models for your specific use case.","sidebar":"sidebar"},"overview":{"id":"overview","title":"Evaluation and Guardrails Overview","description":"Testing is the most important step in both LLM application development and monitoring it\'s behavior in production. In Machine Learning and Artificial Intelligence, testing is referred to by different names depending on when and how you test. When testing an LLM application during development, the process is often referred to as Evaluation. When testing an LLM application\'s behavior during production (typically for an real-time/online use case), the testing is referred to as Guardrails. We\'ll cover both of these in more depth.","sidebar":"sidebar"},"platform":{"id":"platform","title":"AutoEval Platform","description":"The AutoEval fine-tuning platform enables customization of the AlBERTa SLMs to better evaluate and measure your application\'s performance.","sidebar":"sidebar"},"quickstart":{"id":"quickstart","title":"Quickstart","description":"Welcome to the quickstart for getting started with LastMile AI\'s AutoEval platform! This guide will walk you through the basics of the platform.","sidebar":"sidebar"},"sdk":{"id":"sdk","title":"AutoEval Python SDK","description":"PyPI","sidebar":"sidebar"},"summarization":{"id":"summarization","title":"Summarization","description":"A 400M parameter state-of-the-art, encoder based model for calcuating the factual consistency of the generated answer against the provided context."},"toxicity":{"id":"toxicity","title":"Toxicity","description":"A 400M parameter state-of-the-art, encoder based model for calcuating the factual consistency of the generated answer against the provided context."},"workbooks":{"id":"workbooks","title":"AI Workbooks","description":"Workbooks are interactive documents that combine responses from generative AI models to create unique AI-powered applications and workflows. A workbook enables you to string together various generative AI models to build powerful applications. In a workbook, you can connect text, image, and audio models in a single environment.","sidebar":"sidebar"}}}}')}}]);