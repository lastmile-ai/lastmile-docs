/*! For license information please see 3d9c95a4.ced5da8f.js.LICENSE.txt */
(self.webpackChunklastmile_docs=self.webpackChunklastmile_docs||[]).push([[279],{27226:(e,t,a)=>{"use strict";a.r(t),a.d(t,{assets:()=>j,contentTitle:()=>v,default:()=>N,frontMatter:()=>x,metadata:()=>b,toc:()=>y});var r=a(74848),s=a(28453),n=a(4865),i=a(19365),l=(a(79402),a(96540),a(46942)),o=a.n(l);const c={card:"card_kyB9",cardTitle:"cardTitle_WmU7",icon:"icon_xMNd"};function d(e){let{href:t,title:a,description:s,backgroundColor:n,className:i}=e;return(0,r.jsxs)("a",{href:t,className:o()(c.card,i),style:{backgroundColor:n},children:[(0,r.jsxs)("h3",{className:c.cardTitle,children:[a,(0,r.jsx)("span",{className:c.icon,children:">"})]}),(0,r.jsx)("p",{children:s})]})}const u={grid:"grid_qyhz"};function m(e){let{children:t,className:a}=e;return(0,r.jsx)("div",{className:o()(u.grid,a),children:t})}const h={splitPane:"splitPane_bO8i",leftPane:"leftPane_de69",rightPane:"rightPane_Z18N",icon:"icon_QiKa"};function p(e){let{leftChild:t,rightChild:a,className:s,leftPaneClassName:n,rightPaneClassName:i}=e;return(0,r.jsxs)("div",{className:o()(h.splitPane,s),children:[(0,r.jsx)("div",{className:o()(h.leftPane,n),children:t}),(0,r.jsx)("div",{className:o()(h.rightPane,i),children:a})]})}var f=a(52138);function g(e){let{codeBlocks:t,defaultLanguage:a}=e;return(0,r.jsx)(p,{className:"getting-started-card",leftPaneClassName:"getting-started-card-left-pane",rightPaneClassName:"getting-started-card-right-pane",leftChild:(0,r.jsxs)("a",{href:"/getting_started",children:[(0,r.jsx)("h3",{children:"Developer quickstart"}),(0,r.jsx)("p",{children:"Compute your first evaluation metric within 5 minutes."})]}),rightChild:(0,r.jsx)(n.A,{children:t.map((e=>{let{language:t,label:s,code:n}=e;return(0,r.jsx)(i.default,{value:s??t,label:s??t,default:a===t,children:(0,r.jsx)(f.default,{language:t,children:n})},s??t)}))})})}const x={id:"app_home"},v="Introduction",b={id:"app_home",title:"Introduction",description:"LastMile is the full-stack developer platform to debug, evaluate and improve LLM applications. We make it easy to fine-tune custom evaluators, set up guardrails & monitor app performance.",source:"@site/docs/home.md",sourceDirName:".",slug:"/app_home",permalink:"/app_home",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{id:"app_home"},sidebar:"sidebar",next:{title:"Quickstart",permalink:"/quickstart"}},j={},y=[{value:"Meet alBERTa \ud83c\udf41",id:"meet-alberta-",level:2},{value:"Out-of-the-box metrics",id:"out-of-the-box-metrics",level:3},{value:"Design your own metric",id:"design-your-own-metric",level:2},{value:"Explore our guides",id:"explore-our-guides",level:2}];function k(e){const t={h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.header,{children:(0,r.jsx)(t.h1,{id:"introduction",children:"Introduction"})}),"\n",(0,r.jsx)(t.p,{children:"LastMile is the full-stack developer platform to debug, evaluate and improve LLM applications. We make it easy to fine-tune custom evaluators, set up guardrails & monitor app performance."}),"\n",(0,r.jsx)(g,{defaultLanguage:"python",codeBlocks:[{language:"python",code:'from lastmile import LastMile;\nLastMile.eval("Hello world")'},{language:"javascript",label:"node.js",code:"const { LastMile } = require('lastmile');\nLastMile.eval(\"Hello world\");"}]}),"\n",(0,r.jsx)(t.h2,{id:"meet-alberta-",children:"Meet alBERTa \ud83c\udf41"}),"\n",(0,r.jsx)(t.p,{children:"alBERTa is a family of small language models designed for evaluation. They are optimized to be:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"small"})," -- 400M parameter entailment model"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"fast"})," -- can run inference on CPU in < 300ms"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"customizable"})," -- fine-tune for custom evaluation tasks"]}),"\n"]}),"\n",(0,r.jsxs)(m,{className:"alberta-grid",children:[(0,r.jsx)(d,{href:"/alberta",title:"alBERTa-512 \ud83c\udf41",description:"2048 token context, specialized for evaluation tasks (like faithfulness), and gives a numeric 0->1 score.",backgroundColor:"#F5F5F5",className:"custom-card model-512"}),(0,r.jsx)(d,{href:"/alberta",title:"alBERTa-LC-8k \ud83c\udf41",description:"Long-context window variant that can scale to 128k+ tokens using a scaled dot-product attention layer",backgroundColor:"#F5F5F5",className:"custom-card model-8k"})]}),"\n",(0,r.jsx)(t.h3,{id:"out-of-the-box-metrics",children:"Out-of-the-box metrics"}),"\n",(0,r.jsxs)(m,{className:"custom-grid",children:[(0,r.jsx)(d,{href:"/metrics",title:"Faithfulness",description:"Measures how adherent or faithful an LLM response is to the provided context. Often used for hallucination detection.",backgroundColor:"#F1F1F1",className:"custom-card faithfulness"}),(0,r.jsx)(d,{href:"/metrics",title:"Semantic Similarity",description:"Measures semantic similarity between two strings. Often used for context relevance, or input/output relevance, or similarity between a response and ground truth.",backgroundColor:"#F1F1F1",className:"custom-card similarity"}),(0,r.jsx)(d,{href:"/metrics",title:"Summarization Quality",description:"Quantify the quality of a summarization response.",backgroundColor:"#F1F1F1",className:"custom-card summarization"}),(0,r.jsx)(d,{href:"/metrics",title:"Toxicity",description:"Quantify the toxicity level in an LLM response.",backgroundColor:"#F1F1F1",className:"custom-card toxicity"}),(0,r.jsx)(d,{href:"/metrics",title:"More",description:"Explore other metrics available in AutoEval, or keep reading to design your own metric.",backgroundColor:"#F7F7F7",className:"custom-card"})]}),"\n",(0,r.jsx)(t.h2,{id:"design-your-own-metric",children:"Design your own metric"}),"\n",(0,r.jsxs)(m,{className:"custom-grid",children:[(0,r.jsx)(d,{href:"/datasets",title:"Create Datasets",description:"Upload and manage application data for running and training evals, and generate synthetic labels.",backgroundColor:"#FBF6F7",className:"custom-card"}),(0,r.jsx)(d,{href:"/fine_tune",title:"Fine-tune Models",description:"Use the AutoEval fine-tuning service to develop custom metrics for your application.",backgroundColor:"#EFFFF4",className:"custom-card"}),(0,r.jsx)(d,{href:"/serve",title:"Run Evals",description:"Compute metrics by running high-performance inference on a prebuilt or fine-tuned model.",backgroundColor:"#F7EFFF",className:"custom-card"})]}),"\n",(0,r.jsx)(t.h2,{id:"explore-our-guides",children:"Explore our guides"}),"\n",(0,r.jsxs)(m,{className:"guides-grid",children:[(0,r.jsx)(d,{href:"/retrieval_systems",title:"Retrieval systems",description:"Evaluate a RAG application for hallucination, relevance and a custom brand tone metric.",className:"custom-card"}),(0,r.jsx)(d,{href:"/multi_agent",title:"Multi-agent applications",description:"Evaluate end-to-end and intermediate step metrics for a compound AI system.",className:"custom-card"}),(0,r.jsx)(d,{href:"/realtime_guardrails",title:"Real-time guardrails",description:"Use alBERTa \ud83c\udf41 model inference for real-time use-cases, like guardrails.",className:"custom-card"})]})]})}function N(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(k,{...e})}):k(e)}},79402:(e,t,a)=>{"use strict";var r=a(38193);!!r.default.canUseDOM&&navigator.platform.startsWith("Mac"),!!r.default.canUseDOM&&navigator.platform.startsWith("Win")},4865:(e,t,a)=>{"use strict";a.d(t,{A:()=>h});var r=a(96540),s=a(18215),n=a(23104),i=a(47751),l=a(92303);const o={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var c=a(74848);function d(e){let{className:t,block:a,selectedValue:r,selectValue:i,tabValues:l}=e;const d=[],{blockElementScrollPositionUntilNextRender:u}=(0,n.a_)(),m=e=>{const t=e.currentTarget,a=d.indexOf(t),s=l[a].value;s!==r&&(u(t),i(s))},h=e=>{let t=null;switch(e.key){case"Enter":m(e);break;case"ArrowRight":{const a=d.indexOf(e.currentTarget)+1;t=d[a]??d[0];break}case"ArrowLeft":{const a=d.indexOf(e.currentTarget)-1;t=d[a]??d[d.length-1];break}}t?.focus()};return(0,c.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,s.A)("tabs",{"tabs--block":a},t),children:l.map((e=>{let{value:t,label:a,attributes:n}=e;return(0,c.jsx)("li",{role:"tab",tabIndex:r===t?0:-1,"aria-selected":r===t,ref:e=>d.push(e),onKeyDown:h,onClick:m,...n,className:(0,s.A)("tabs__item",o.tabItem,n?.className,{"tabs__item--active":r===t}),children:a??t},t)}))})}function u(e){let{lazy:t,children:a,selectedValue:n}=e;const i=(Array.isArray(a)?a:[a]).filter(Boolean);if(t){const e=i.find((e=>e.props.value===n));return e?(0,r.cloneElement)(e,{className:(0,s.A)("margin-top--md",e.props.className)}):null}return(0,c.jsx)("div",{className:"margin-top--md",children:i.map(((e,t)=>(0,r.cloneElement)(e,{key:t,hidden:e.props.value!==n})))})}function m(e){const t=(0,i.u)(e);return(0,c.jsxs)("div",{className:(0,s.A)("tabs-container",o.tabList),children:[(0,c.jsx)(d,{...t,...e}),(0,c.jsx)(u,{...t,...e})]})}function h(e){const t=(0,l.default)();return(0,c.jsx)(m,{...e,children:(0,i.v)(e.children)},String(t))}},46942:(e,t)=>{var a;!function(){"use strict";var r={}.hasOwnProperty;function s(){for(var e="",t=0;t<arguments.length;t++){var a=arguments[t];a&&(e=i(e,n(a)))}return e}function n(e){if("string"==typeof e||"number"==typeof e)return e;if("object"!=typeof e)return"";if(Array.isArray(e))return s.apply(null,e);if(e.toString!==Object.prototype.toString&&!e.toString.toString().includes("[native code]"))return e.toString();var t="";for(var a in e)r.call(e,a)&&e[a]&&(t=i(t,a));return t}function i(e,t){return t?e?e+" "+t:e+t:e}e.exports?(s.default=s,e.exports=s):void 0===(a=function(){return s}.apply(t,[]))||(e.exports=a)}()}}]);