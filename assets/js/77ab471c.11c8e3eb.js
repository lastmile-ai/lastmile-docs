"use strict";(self.webpackChunklastmile_docs=self.webpackChunklastmile_docs||[]).push([[7567],{26770:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>h,contentTitle:()=>l,default:()=>p,frontMatter:()=>r,metadata:()=>c,toc:()=>d});var i=t(74848),s=t(28453),a=t(4865),o=t(19365);t(79402);const r={title:"Evaluation Metrics"},l=void 0,c={id:"autoeval/metrics",title:"Evaluation Metrics",description:"Out-of-the-box metrics for common AI applications",source:"@site/docs/autoeval/metrics.mdx",sourceDirName:"autoeval",slug:"/autoeval/metrics",permalink:"/autoeval/metrics",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{title:"Evaluation Metrics"},sidebar:"sidebar",previous:{title:"Introduction",permalink:"/autoeval/autoeval-intro"},next:{title:"Manage Datasets",permalink:"/autoeval/datasets"}},h={},d=[{value:"Hallucination Detection (Faithfulness)",id:"hallucination-detection-faithfulness",level:3},{value:"Definition",id:"definition",level:4},{value:"Usage Guide",id:"usage-guide",level:4},{value:"Explanation",id:"explanation",level:5},{value:"Summarization Score",id:"summarization-score",level:3},{value:"Usage Guide",id:"usage-guide-1",level:4},{value:"Explanation",id:"explanation-1",level:5},{value:"Relevance",id:"relevance",level:3},{value:"Usage Guide",id:"usage-guide-2",level:4},{value:"Explanation",id:"explanation-2",level:5},{value:"Answer Correctness",id:"answer-correctness",level:3},{value:"Usage Guide",id:"usage-guide-3",level:4},{value:"Explanation",id:"explanation-3",level:5},{value:"Output Quality Evaluators",id:"output-quality-evaluators",level:3},{value:"Exact Match",id:"exact-match",level:4},{value:"BLEU",id:"bleu",level:4},{value:"ROUGE",id:"rouge",level:4},{value:"Usage Guide",id:"usage-guide-4",level:4},{value:"Examples",id:"examples",level:4},{value:"Safety Evaluators",id:"safety-evaluators",level:2},{value:"Toxicity",id:"toxicity",level:3},{value:"Usage Guide",id:"usage-guide-5",level:4}];function u(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h2:"h2",h3:"h3",h4:"h4",h5:"h5",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.p,{children:"Out-of-the-box metrics for common AI applications"}),"\n",(0,i.jsx)(n.admonition,{type:"info",children:(0,i.jsxs)(n.p,{children:["This section covers metrics available out-of-the-box in AutoEval.\nYou can also ",(0,i.jsx)(n.a,{href:"/autoeval/fine-tune",children:"fine-tune your own metric"}),"."]})}),"\n",(0,i.jsx)(n.p,{children:"All evaluators work on some combination of the following properties:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"input"}),": Input to the application (e.g. a user question for a Q&A system)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"output"}),": The response generated by the application (e.g. LLM generation)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"ground_truth"}),": Factual data, either the ideal correct response, or context used to generate the output (e.g. data retrieved from a vector DB)"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Running evals is possible both from the ",(0,i.jsx)(n.a,{href:"https://lastmileai.dev/models",children:"Model Console"})," dashboard as well as the ",(0,i.jsx)(n.a,{href:"/sdk",children:"API"}),"."]}),"\n",(0,i.jsxs)(n.p,{children:["You can run a one-off evaluation from the model playground. Open any metric in the ",(0,i.jsx)(n.a,{href:"https://lastmileai.dev/models",children:"Model Console"}),",\nand click ",(0,i.jsx)(n.code,{children:"Run Model"})," (the play button) to compute a score on some provided data."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Model Playground",src:t(6569).A+"",width:"2674",height:"972"})}),"\n",(0,i.jsx)(n.h3,{id:"hallucination-detection-faithfulness",children:"Hallucination Detection (Faithfulness)"}),"\n",(0,i.jsx)(n.h4,{id:"definition",children:"Definition"}),"\n",(0,i.jsxs)(n.p,{children:["Given an input, measures the faithfulness of an LLM-generated output to the provided context or ground truth. It returns a 0->1 probability score\nwhich answers ",(0,i.jsx)(n.em,{children:"\u201cTo what extent is the generated answer faithful to the provided context without introducing unsupported information?\u201d"})]}),"\n",(0,i.jsx)(n.p,{children:"It is particularly useful in RAG applications, and a good proxy for hallucination detection.\nThe task is a Natural Language Inference (NLI) task that measures if the output can be logically inferred from the context and input."}),"\n",(0,i.jsx)(n.p,{children:"Required fields:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"input"})," - e.g. user query"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"output"})," - LLM response"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"ground_truth"})," - ideal response, or context used to generate output."]}),"\n"]}),"\n",(0,i.jsx)(n.admonition,{type:"tip",children:(0,i.jsxs)(n.p,{children:["The LastMile faithfulness evaluator is able to identify subtle mistakes that an LLM might make.\nFor example, in a customer service assistant, for a ",(0,i.jsx)(n.em,{children:'"What is the customer service phone number?"'})," query,\nif the LLM even subtly misses the number (e.g. 123-546-7890 instead of 123-456-7890), the faithfulness detector\nwill catch it. Give it a try!"]})}),"\n",(0,i.jsx)(n.h4,{id:"usage-guide",children:"Usage Guide"}),"\n",(0,i.jsxs)(a.A,{groupId:"faithfulness-example",children:[(0,i.jsx)(o.default,{value:"python",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from lastmile.lib.auto_eval import AutoEval, BuiltinMetrics\nimport pandas as pd\n\nclient = AutoEval(api_token="api_token_if_LASTMILE_API_TOKEN_not_set")\n\nquery = "What is Albert Einstein famous for?"\ncontext_retrieved = """\n  Albert Einstein was a German-born theoretical physicist who developed\n  the theory of relativity, one of the two pillars of modern physics. His\n  work is also known for its influence on the philosophy of science. He is\n  best known to the general public for his mass-energy equivalence formula\n  E = mc\xb2, which has been dubbed \'the world\'s most famous equation\'. He\n  received the 1921 Nobel Prize in Physics \'for his services to theoretical\n  physics, and especially for his discovery of the law of the photoelectric\n  effect\', a pivotal step in the development of quantum theory."""\n\nllm_response = "Albert Einstein is famous for the formula E = mc\xb2 and Brownian motion."\n\neval_result = client.evaluate_data(\n  data=pd.DataFrame({\n      "input": [query],\n      "output": [llm_response],\n      "ground_truth": [context_retrieved]\n  }),\n  metrics=[BuiltinMetrics.FAITHFULNESS]\n)\n\nprint(eval_result)\n'})})}),(0,i.jsx)(o.default,{value:"node.js",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:'import { AutoEval, BuiltinMetrics } from "lastmile/lib/auto_eval";\n\nconst client = new AutoEval({\n  apiKey: "api_token_if_LASTMILE_API_TOKEN_not_set",\n});\n\nconst query = "What is Albert Einstein famous for?";\nconst contextRetrieved = `\n  Albert Einstein was a German-born theoretical physicist who developed\n  the theory of relativity, one of the two pillars of modern physics. His\n  work is also known for its influence on the philosophy of science. He is\n  best known to the general public for his mass-energy equivalence formula\n  E = mc\xb2, which has been dubbed \'the world\'s most famous equation\'. He\n  received the 1921 Nobel Prize in Physics \'for his services to theoretical\n  physics, and especially for his discovery of the law of the photoelectric\n  effect\', a pivotal step in the development of quantum theory.`;\n\nconst llmResponse = "Albert Einstein is famous for the formula E = mc\xb2 and Brownian motion.";\n\n// Evaluate data using the FAITHFULNESS metric\nconst evalResult = await client.evaluateData(\n  [\n    {\n      "input": query,\n      "output": llmResponse,\n      "ground_truth": contextRetrieved,\n    },\n  ],\n  [BuiltinMetrics.FAITHFULNESS]\n);\n\nconsole.table(evalResult);\n'})})})]}),"\n",(0,i.jsx)("img",{width:"1000",alt:"faithful",src:"https://github.com/lastmile-ai/aiconfig/assets/81494782/912eecca-fcd2-41e9-871b-09a36a5f1258"}),"\n",(0,i.jsx)(n.h5,{id:"explanation",children:"Explanation"}),"\n",(0,i.jsx)(n.p,{children:"The faithfulness score of 0.66 suggests that the LLM-generated response is only partially faithful to the retrieved context. While it correctly mentions Einstein's famous equation, E = mc\xb2, it also includes information about Brownian motion, which is not present in the context. The inclusion of this additional information likely contributed to the lower score, indicating that the LLM relied on its own knowledge beyond the given context."}),"\n",(0,i.jsx)(n.h3,{id:"summarization-score",children:"Summarization Score"}),"\n",(0,i.jsxs)(n.p,{children:["The Summarization evaluator measures the quality of an LLM-generated summary compared to the source document.\nIt aims to assess how well the summary captures the essential information and main ideas of the source document.\nIt returns a 0->1 score which answers: ",(0,i.jsx)(n.em,{children:'"To what extent does the generated summary capture the essential information from the source document?"'})]}),"\n",(0,i.jsx)(n.p,{children:"Required fields:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"output"})," - LLM generated summary"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"ground_truth"})," - source document (e.g. context used to generate output)"]}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"usage-guide-1",children:"Usage Guide"}),"\n",(0,i.jsxs)(a.A,{groupId:"summarization-example",children:[(0,i.jsx)(o.default,{value:"python",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from lastmile.lib.auto_eval import AutoEval, BuiltinMetrics\nimport pandas as pd\n\nclient = AutoEval(api_token="api_token_if_LASTMILE_API_TOKEN_not_set")\n\nsource_document = """\n  Albert Einstein was a German-born theoretical physicist who developed\n  the theory of relativity, one of the two pillars of modern physics. His work\n  is also known for its influence on the philosophy of science. He is best known\n  to the general public for his mass-energy equivalence formula E = mc\xb2,\n  which has been dubbed \'the world\'s most famous equation\'. Einstein received\n  the 1921 Nobel Prize in Physics \'for his services to theoretical physics, and\n  especially for his discovery of the law of the photoelectric effect\', a\n  pivotal step in the development of quantum theory. In his later years,\n  Einstein focused on unified field theory and became increasingly isolated\n  from the mainstream of modern physics."""\n\nllm_summary = """\n  Albert Einstein, a German-born physicist, developed the theory of\n  relativity and the famous equation E = mc\xb2. He won the 1921 Nobel Prize\n  in Physics for his work on the photoelectric effect, contributing to\n  quantum theory. Later, he worked on unified field theory."""\n\neval_result = client.evaluate_data(\n  data=pd.DataFrame({\n      "output": [llm_summary],\n      "ground_truth": [source_document]\n  }),\n  metrics=[BuiltinMetrics.SUMMARIZATION]\n)\n\nprint(eval_result)\n'})})}),(0,i.jsx)(o.default,{value:"node.js",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:'import { AutoEval, BuiltinMetrics } from "lastmile/lib/auto_eval";\n\nconst client = new AutoEval({\n  apiKey: "api_token_if_LASTMILE_API_TOKEN_not_set",\n});\n\nconst sourceDocument = `\n  Albert Einstein was a German-born theoretical physicist who developed\n  the theory of relativity, one of the two pillars of modern physics. His work\n  is also known for its influence on the philosophy of science. He is best known\n  to the general public for his mass-energy equivalence formula E = mc\xb2,\n  which has been dubbed \'the world\'s most famous equation\'. Einstein received\n  the 1921 Nobel Prize in Physics \'for his services to theoretical physics, and\n  especially for his discovery of the law of the photoelectric effect\', a\n  pivotal step in the development of quantum theory. In his later years,\n  Einstein focused on unified field theory and became increasingly isolated\n  from the mainstream of modern physics.`;\n\nconst llmSummary = `\n  Albert Einstein, a German-born physicist, developed the theory of\n  relativity and the famous equation E = mc\xb2. He won the 1921 Nobel Prize\n  in Physics for his work on the photoelectric effect, contributing to\n  quantum theory. Later, he worked on unified field theory.`;\n\n// Evaluate data using the SUMMARIZATION metric\nconst evalResult = await client.evaluateData(\n  [\n    {\n      "output": llmSummary,\n      "ground_truth": sourceDocument,\n    },\n  ],\n  [BuiltinMetrics.SUMMARIZATION]\n);\n\nconsole.table(evalResult);\n'})})})]}),"\n",(0,i.jsx)("img",{width:"1000",alt:"summarization",src:"https://github.com/lastmile-ai/aiconfig/assets/81494782/57bf8fe1-8d47-43f4-b175-91e7bf338056"}),"\n",(0,i.jsx)(n.h5,{id:"explanation-1",children:"Explanation"}),"\n",(0,i.jsx)(n.p,{children:"The summarization score of 0.88 indicates the summary effectively captures key points about Einstein, including his German origin, development of relativity theory, E = mc\xb2 equation, 1921 Nobel Prize for the photoelectric effect, and work on unified field theory.\nIt successfully condenses essential information while maintaining accuracy. The score isn't perfect, likely due to omitting Einstein's influence on philosophy of science and his later isolation from mainstream physics."}),"\n",(0,i.jsx)(n.h3,{id:"relevance",children:"Relevance"}),"\n",(0,i.jsx)(n.p,{children:"The Relevance evaluator measures the semantic similarity between two strings.\nIt can be used to compare"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"response relevancy"})," -- how relevant is the generated output to the input prompt?"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"context relevancy"})," -- how relevant is the generated output to the context retrieved?"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"answer equivalence"})," -- how similar is the generated output to a ground truth expected response?"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Required fields:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"input"})," - one string to compare (e.g. input query)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"output"})," - second string to compare (e.g. generated response)"]}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"usage-guide-2",children:"Usage Guide"}),"\n",(0,i.jsxs)(a.A,{groupId:"relevance-example",children:[(0,i.jsx)(o.default,{value:"python",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from lastmile.lib.auto_eval import AutoEval, BuiltinMetrics\nimport pandas as pd\n\nclient = AutoEval(api_token="api_token_if_LASTMILE_API_TOKEN_not_set")\n\nllm_response ="""\n  Albert Einstein revolutionized physics with his theory of relativity.\n  He proposed that space and time are interconnected and that the speed of\n  light is constant in all reference frames. His famous equation E = mc\xb2\n  showed that mass and energy are equivalent. Einstein\'s work on the\n  photoelectric effect contributed to the development of quantum theory,\n  earning him the Nobel Prize in Physics."""\n\nexpected_response = """\n  Albert Einstein transformed our understanding of the universe with his\n  groundbreaking theories. His special and general theories of relativity\n  redefined concepts of space, time, and gravity. Einstein\'s equation E = mc\xb2\n  revealed the fundamental relationship between mass and energy. His\n  explanation of the photoelectric effect was crucial to the emergence of\n  quantum physics, for which he received the Nobel Prize. Throughout his career,\n  Einstein\'s innovative thinking and scientific contributions reshaped the\n  field of physics."""\n\neval_result = client.evaluate_data(\n  data=pd.DataFrame({\n      "input": [expected_response],\n      "output": [llm_response],\n  }),\n  metrics=[BuiltinMetrics.RELEVANCE]\n)\n\nprint(eval_result)\n'})})}),(0,i.jsx)(o.default,{value:"node.js",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:'import { AutoEval, BuiltinMetrics } from "lastmile/lib/auto_eval";\n\nconst client = new AutoEval({\n  apiKey: "api_token_if_LASTMILE_API_TOKEN_not_set",\n});\n\nconst expectedResponse = `\n  Albert Einstein transformed our understanding of the universe with his\n  groundbreaking theories. His special and general theories of relativity\n  redefined concepts of space, time, and gravity. Einstein\'s equation E = mc\xb2\n  revealed the fundamental relationship between mass and energy. His\n  explanation of the photoelectric effect was crucial to the emergence of\n  quantum physics, for which he received the Nobel Prize. Throughout his career,\n  Einstein\'s innovative thinking and scientific contributions reshaped the\n  field of physics.`;\n\nconst llmResponse = `\n  Albert Einstein revolutionized physics with his theory of relativity.\n  He proposed that space and time are interconnected and that the speed of\n  light is constant in all reference frames. His famous equation E = mc\xb2\n  showed that mass and energy are equivalent. Einstein\'s work on the\n  photoelectric effect contributed to the development of quantum theory,\n  earning him the Nobel Prize in Physics.`;\n\nconst evalResult = await client.evaluateData(\n  [\n    {\n      "input": expectedResponse,\n      "output": llmResponse,\n    },\n  ],\n  [BuiltinMetrics.RELEVANCE]\n);\n\nconsole.table(evalResult);\n'})})})]}),"\n",(0,i.jsx)("img",{width:"1000",alt:"relevance",src:"https://github.com/lastmile-ai/aiconfig/assets/81494782/66cb897e-8063-4054-a9dd-3bcc9036b029"}),"\n",(0,i.jsx)(n.h5,{id:"explanation-2",children:"Explanation"}),"\n",(0,i.jsx)(n.p,{children:"The relevance score of 0.94 indicates high alignment between the LLM-generated response and the expected output.\nBoth texts cover Einstein's key contributions: the theory of relativity, E = mc\xb2, and the photoelectric effect.\nThe score isn't perfect, as the LLM response omits mentions of general relativity and Einstein's broader impact on physics.\nHowever, it adds relevant details about light's constant speed.\nOverall, the high score reflects strong topical relevance and accurate conveyance of Einstein's main scientific achievements."}),"\n",(0,i.jsx)(n.h3,{id:"answer-correctness",children:"Answer Correctness"}),"\n",(0,i.jsxs)(n.p,{children:["The Answer Correctness evaluator is a binary measure of whether an LLM-generated response answers a user query based on the retrieved context.\nIt aims to evaluate the accuracy and completeness of the answer in relation to the provided information.\nIt returns a 0->1 score which answers: ",(0,i.jsx)(n.em,{children:'"Does the LLM-generated response correctly and completely answer the user query based on the retrieved context?"'})]}),"\n",(0,i.jsx)(n.p,{children:"Required fields:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"input"})," - Input prompt"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"output"})," - LLM response"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"ground_truth"})," - context used to generate output."]}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"usage-guide-3",children:"Usage Guide"}),"\n",(0,i.jsxs)(a.A,{groupId:"answer-correctness-example",children:[(0,i.jsx)(o.default,{value:"python",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from lastmile.lib.auto_eval import AutoEval, BuiltinMetrics\nimport pandas as pd\n\nclient = AutoEval(api_token="api_token_if_LASTMILE_API_TOKEN_not_set")\n\nquery = "Can you tell me the flight status for SA450?"\ncontext_retrieved = "Flight SA450 is on schedule and will depart from JFK Terminal 2, Gate 15 at 4:00PM."\nllm_response = "SA450: On Schedule, JFK Terminal 2, Gate 15, 4:00PM departure"\n\neval_result = client.evaluate_data(\n  data=pd.DataFrame({\n      "input": [query],\n      "output": [llm_response],\n      "ground_truth": [context_retrieved]\n  }),\n  metrics=[BuiltinMetrics.ANSWER_CORRECTNESS]\n)\n\nprint(eval_result)\n'})})}),(0,i.jsx)(o.default,{value:"node.js",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:'import { AutoEval, BuiltinMetrics } from "lastmile/lib/auto_eval";\n\nconst client = new AutoEval({\n  apiKey: "api_token_if_LASTMILE_API_TOKEN_not_set",\n});\n\nconst query = "Can you tell me the flight status for SA450?";\nconst contextRetrieved = "Flight SA450 is on schedule and will depart from JFK Terminal 2, Gate 15 at 4:00PM.";\nconst llmResponse = "SA450: On Schedule, JFK Terminal 2, Gate 15, 4:00PM departure";\n\nconst evalResult = await client.evaluateData(\n  [\n    {\n      "input": query,\n      "output": llmResponse,\n      "ground_truth": contextRetrieved\n    },\n  ],\n  [BuiltinMetrics.ANSWER_CORRECTNESS]\n);\n\nconsole.table(evalResult);\n'})})})]}),"\n",(0,i.jsx)(n.h5,{id:"explanation-3",children:"Explanation"}),"\n",(0,i.jsxs)(n.p,{children:["The above yields a score of ",(0,i.jsx)(n.code,{children:"0.999"}),", indicating the LLM response fully and accurately answers the query based on the context.\n",(0,i.jsx)(n.img,{alt:"Answer Equivalence Good",src:t(80230).A+"",width:"2682",height:"996"})]}),"\n",(0,i.jsxs)(n.p,{children:["Now try changing the generated response time from ",(0,i.jsx)(n.code,{children:"4:00pm"})," to ",(0,i.jsx)(n.code,{children:"4:01pm"}),", a very subtle change.\nDoing so yields a score of ",(0,i.jsx)(n.code,{children:"0.007"}),", as expected.\n",(0,i.jsx)(n.img,{alt:"Answer Equivalence Bad",src:t(77789).A+"",width:"2684",height:"1026"})]}),"\n",(0,i.jsx)(n.h3,{id:"output-quality-evaluators",children:"Output Quality Evaluators"}),"\n",(0,i.jsx)(n.p,{children:"In addition to the above, there are a few metrics for response quality which can be helpful.\nWe list them here for completeness, but don't provide them in AutoEval since they are easy to calculate on your own (see Usage Guide below):"}),"\n",(0,i.jsx)(n.h4,{id:"exact-match",children:"Exact Match"}),"\n",(0,i.jsxs)(n.p,{children:["Exact Match is a fancy way of saying string equals. It assesses whether an LLM-generated response is identical to a reference text.\nIt provides a binary score indicating perfect string matching.\nThe Exact Match score answers: ",(0,i.jsx)(n.em,{children:'"Is the LLM-generated response exactly the same as the reference text?"'})]}),"\n",(0,i.jsx)(n.h4,{id:"bleu",children:"BLEU"}),"\n",(0,i.jsxs)(n.p,{children:['The BLEU (Bilingual Evaluation Understudy) score measures how similar a machine-generated text is to a reference text.\nIt does this by comparing overlapping words and phrases, including sequences of words called n-grams.\nThe BLEU score answers: _"How closely does the LLM-generated text match the reference text in terms of word and phrase usage?" ',(0,i.jsx)(n.a,{href:"https://towardsdatascience.com/foundations-of-nlp-explained-bleu-score-and-wer-metrics-1a5ba06d812b",children:"Learn more"}),"."]}),"\n",(0,i.jsx)(n.h4,{id:"rouge",children:"ROUGE"}),"\n",(0,i.jsxs)(n.p,{children:["The ROUGE (Recall-Oriented Understudy for Gisting Evaluation) score measures how well a machine-generated summary captures the content of a reference summary.\nUnlike BLEU, which focuses on precision, ROUGE emphasizes recall, assessing how much of the reference content is present in the generated text.\nThe ROUGE score answers: ",(0,i.jsx)(n.em,{children:'"How well does the LLM-generated summary cover the key information from the reference summary?"'})," ",(0,i.jsx)(n.a,{href:"https://medium.com/nlplanet/two-minutes-nlp-learn-the-rouge-metric-by-examples-f179cc285499",children:"Learn more"}),"."]}),"\n",(0,i.jsx)(n.h4,{id:"usage-guide-4",children:"Usage Guide"}),"\n",(0,i.jsx)(a.A,{groupId:"pacman",children:(0,i.jsx)(o.default,{value:"pip",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"pip install nltk rouge-score\n"})})})}),"\n",(0,i.jsx)(a.A,{groupId:"output-quality-functions",children:(0,i.jsx)(o.default,{value:"python",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from nltk.translate.bleu_score import sentence_bleu\nfrom rouge_score import rouge_scorer\nimport numpy as np\n\ndef calculate_bleu(reference, hypothesis):\n  """\n  Calculate BLEU score for a single reference and hypothesis.\n  :param reference: List of tokens for the reference sentence.\n  :param hypothesis: List of tokens for the hypothesis sentence.\n  :return: BLEU score.\n  """\n  return sentence_bleu([reference], hypothesis)\n\ndef calculate_rouge(reference, hypothesis):\n  """\n  Calculate ROUGE scores for a single reference and hypothesis.\n  :param reference: Reference sentence as a string.\n  :param hypothesis: Hypothesis sentence as a string.\n  :return: Dictionary with ROUGE-1, ROUGE-2, and ROUGE-L scores.\n  """\n  scorer = rouge_scorer.RougeScorer([\'rouge1\', \'rouge2\', \'rougeL\'], use_stemmer=True)\n  scores = scorer.score(reference, hypothesis)\n  return {key: value.fmeasure for key, value in scores.items()}\n\ndef calculate_exact_match(reference, hypothesis):\n  """\n  Calculate exact match score for a single reference and hypothesis.\n  :param reference: Reference sentence as a string.\n  :param hypothesis: Hypothesis sentence as a string.\n  :return: Exact match score (1.0 if exact match, 0.0 otherwise).\n  """\n  return 1.0 if reference.strip() == hypothesis.strip() else 0.0\n'})})})}),"\n",(0,i.jsx)(n.h4,{id:"examples",children:"Examples"}),"\n",(0,i.jsxs)(a.A,{groupId:"output-quality-examples",children:[(0,i.jsxs)(o.default,{value:"BLEU",children:[(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'llm_response = """\n  Einstein developed the theory of relativity, which changed\n  our understanding of space and time."""\n\nground_truth = """\n  Einstein created the theory of relativity that revolutionized\n  our view of space and time."""\n\nbleu_score = calculate_bleu(\n  ground_truth,\n  llm_response\n)\n'})}),(0,i.jsx)("img",{width:"1000",alt:"relevance",src:"https://github.com/lastmile-ai/aiconfig/assets/81494782/2f6a0dae-4bde-431c-aaac-2d0716ca5699"}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Explanation"}),':\nThe BLEU Score of 0.4 shows moderate similarity between the texts.\nBoth convey the core idea about Einstein\'s theory of relativity, but differ in specific wording (e.g., "developed" vs. "created").\nThis score reflects BLEU\'s sensitivity to exact word matches and order, highlighting why it should be used ',(0,i.jsx)(n.em,{children:"alongside"})," other metrics for comprehensive evaluation."]})]}),(0,i.jsxs)(o.default,{value:"ROUGE",children:[(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'llm_response = """\n  Einstein\'s theory of relativity revolutionized physics by unifying space and time.\n  It introduced the concept of spacetime and showed that massive objects can warp it.\n  The theory also led to the famous equation E=mc\xb2, relating mass and energy."""\n\nground_truth = """\n  Einstein\'s theory of relativity transformed our understanding of the universe.\n  It combined space and time into a single continuum called spacetime, which can be\n  distorted by mass and energy. The theory\'s most famous outcome is the equation E=mc\xb2,\n  demonstrating the equivalence of mass and energy."""\n\nrouge_scores = calculate_rouge(\n  ground_truth,\n  llm_response\n)\n'})}),(0,i.jsx)("img",{width:"1000",alt:"relevance",src:"https://github.com/lastmile-ai/aiconfig/assets/81494782/32052c1a-c904-49d6-917d-c49fbc44d3f2"}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Explanation"}),":\nThe ROUGE1 Score of 0.56 indicates moderate content overlap between the generated and reference summaries.\nBoth capture key aspects of Einstein's theory of relativity, including the unification of space and time, spacetime concept, and the E=mc\xb2 equation.\nHowever, the score suggests some differences in coverage or phrasing. This demonstrates how ROUGE evaluates summary quality based on shared content, balancing similarities and variations in expression."]})]}),(0,i.jsxs)(o.default,{value:"Exact Match",children:[(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'llm_response = "E = mc^2 is Einstein\'s famous equation relating energy and mass."\nground_truth = "E = mc^2 is Einstein\'s famous equation relating energy and mass."\n\nexact_match_score = calculate_exact_match(\n  ground_truth,\n  llm_response\n)\n'})}),(0,i.jsx)("img",{width:"1000",alt:"relevance",src:"https://github.com/lastmile-ai/aiconfig/assets/81494782/0680fb06-0271-4683-ba22-2818b9196712"}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Explanation"}),":\nThe Exact Match score of 1 indicates the LLM-generated response perfectly matches the reference text.\nThis score is useful for verifying precise reproduction of expected outputs."]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"safety-evaluators",children:"Safety Evaluators"}),"\n",(0,i.jsx)(n.p,{children:"Safety Evaluators assess the appropriateness and potential harm of LLM-generated content."}),"\n",(0,i.jsx)(n.h3,{id:"toxicity",children:"Toxicity"}),"\n",(0,i.jsxs)(n.p,{children:["The Toxicity evaluator assesses whether an LLM-generated response contains toxic content.\nIt aims to identify harmful, offensive, or inappropriate elements in the generated text.\nThe Toxicity score answers: ",(0,i.jsx)(n.em,{children:'"Does the LLM-generated response contain any form of toxic content?"'})]}),"\n",(0,i.jsx)(n.admonition,{type:"tip",children:(0,i.jsxs)(n.p,{children:["You can also use the Toxicity evaluator to measure ",(0,i.jsx)(n.em,{children:"input"})," toxicity."]})}),"\n",(0,i.jsx)(n.p,{children:"Required fields:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"output"})," - LLM response to assess toxicity for"]}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"usage-guide-5",children:"Usage Guide"}),"\n",(0,i.jsxs)(a.A,{groupId:"toxicity-example",children:[(0,i.jsx)(o.default,{value:"python",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from lastmile.lib.auto_eval import AutoEval, BuiltinMetrics\nimport pandas as pd\n\nclient = AutoEval(api_token="api_token_if_LASTMILE_API_TOKEN_not_set")\n\neval_result = client.evaluate_data(\n  data=pd.DataFrame({\n      "output": ["This is the worst airline I\'ve ever flown with. You\'ve lost my bags!"],\n  }),\n  metrics=[BuiltinMetrics.TOXICITY]\n)\n\nprint(eval_result)\n'})})}),(0,i.jsx)(o.default,{value:"node.js",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:'import { AutoEval, BuiltinMetrics } from "lastmile/lib/auto_eval";\n\nconst client = new AutoEval({\n  apiKey: "api_token_if_LASTMILE_API_TOKEN_not_set",\n});\n\nconst evalResult = await client.evaluateData(\n  [\n    {\n      "output": "This is the worst airline I\'ve ever flown with. You\'ve lost my bags!",\n    },\n  ],\n  [BuiltinMetrics.TOXICITY]\n);\n\nconsole.table(evalResult);\n'})})})]}),"\n",(0,i.jsx)(n.admonition,{type:"info",children:(0,i.jsxs)(n.p,{children:["Don't see a metric that perfectly fits your use case? ",(0,i.jsx)(n.a,{href:"/autoeval/fine-tune",children:"Design your own"})," with the fine-tuning service, or ",(0,i.jsx)(n.a,{href:"https://discord.com/invite/xBhNKTetGx",children:"get in touch"}),"!"]})})]})}function p(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(u,{...e})}):u(e)}},79402:(e,n,t)=>{var i=t(38193);!!i.default.canUseDOM&&navigator.platform.startsWith("Mac"),!!i.default.canUseDOM&&navigator.platform.startsWith("Win")},4865:(e,n,t)=>{t.d(n,{A:()=>p});var i=t(96540),s=t(18215),a=t(23104),o=t(47751),r=t(92303);const l={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var c=t(74848);function h(e){let{className:n,block:t,selectedValue:i,selectValue:o,tabValues:r}=e;const h=[],{blockElementScrollPositionUntilNextRender:d}=(0,a.a_)(),u=e=>{const n=e.currentTarget,t=h.indexOf(n),s=r[t].value;s!==i&&(d(n),o(s))},p=e=>{let n=null;switch(e.key){case"Enter":u(e);break;case"ArrowRight":{const t=h.indexOf(e.currentTarget)+1;n=h[t]??h[0];break}case"ArrowLeft":{const t=h.indexOf(e.currentTarget)-1;n=h[t]??h[h.length-1];break}}n?.focus()};return(0,c.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,s.A)("tabs",{"tabs--block":t},n),children:r.map((e=>{let{value:n,label:t,attributes:a}=e;return(0,c.jsx)("li",{role:"tab",tabIndex:i===n?0:-1,"aria-selected":i===n,ref:e=>h.push(e),onKeyDown:p,onClick:u,...a,className:(0,s.A)("tabs__item",l.tabItem,a?.className,{"tabs__item--active":i===n}),children:t??n},n)}))})}function d(e){let{lazy:n,children:t,selectedValue:a}=e;const o=(Array.isArray(t)?t:[t]).filter(Boolean);if(n){const e=o.find((e=>e.props.value===a));return e?(0,i.cloneElement)(e,{className:(0,s.A)("margin-top--md",e.props.className)}):null}return(0,c.jsx)("div",{className:"margin-top--md",children:o.map(((e,n)=>(0,i.cloneElement)(e,{key:n,hidden:e.props.value!==a})))})}function u(e){const n=(0,o.u)(e);return(0,c.jsxs)("div",{className:(0,s.A)("tabs-container",l.tabList),children:[(0,c.jsx)(h,{...n,...e}),(0,c.jsx)(d,{...n,...e})]})}function p(e){const n=(0,r.default)();return(0,c.jsx)(u,{...e,children:(0,o.v)(e.children)},String(n))}},80230:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/answer_correctness_a-f070e2ee979892750b2e2afad22a55ba.png"},77789:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/answer_correctness_b-33a9559aae1bd02d2a1e5c4e0cb28847.png"},6569:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/playground_quickstart-1c8b26a79818e98277cd00bdb70511aa.png"}}]);