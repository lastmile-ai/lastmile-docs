"use strict";(self.webpackChunklastmile_docs=self.webpackChunklastmile_docs||[]).push([[876],{7726:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>o,contentTitle:()=>s,default:()=>h,frontMatter:()=>l,metadata:()=>r,toc:()=>c});var n=a(4848),i=a(8453);a(4865),a(9365),a(9402);const l={id:"autoeval-platform"},s="The AutoEval Platform",r={id:"autoeval-platform",title:"The AutoEval Platform",description:"LastMile AI's AutoEval Platform enables companies to evaluate and measure the quality of responses from their Large-Language Models (LLMs) and Retrieval-Augmented Generation (RAG) applications. The AutoEval Platform uses Small Language Models (SLMs) with machine learning techniques in the platform to accurately evaluate and measure the performance of LLMs.",source:"@site/docs/autoeval-platform.md",sourceDirName:".",slug:"/autoeval-platform",permalink:"/docs/autoeval-platform",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{id:"autoeval-platform"},sidebar:"sidebar",next:{title:"Evaluation, Testing, and Guardrails Overview",permalink:"/docs/overview"}},o={},c=[{value:"SLMs",id:"slms",level:3},{value:"AlBERTa-512",id:"alberta-512",level:5},{value:"AlBERTa-LC-8k",id:"alberta-lc-8k",level:5},{value:"Platform",id:"platform",level:3},{value:"Platform Capabilities",id:"platform-capabilities",level:4},{value:"1. Synthetic Data Generation",id:"1-synthetic-data-generation",level:5},{value:"2. Fine-tuning",id:"2-fine-tuning",level:5},{value:"3. Active Learning",id:"3-active-learning",level:5},{value:"4. Deployment",id:"4-deployment",level:5}];function d(e){const t={em:"em",h1:"h1",h3:"h3",h4:"h4",h5:"h5",header:"header",img:"img",p:"p",strong:"strong",...(0,i.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.header,{children:(0,n.jsx)(t.h1,{id:"the-autoeval-platform",children:"The AutoEval Platform"})}),"\n",(0,n.jsx)(t.p,{children:"LastMile AI's AutoEval Platform enables companies to evaluate and measure the quality of responses from their Large-Language Models (LLMs) and Retrieval-Augmented Generation (RAG) applications. The AutoEval Platform uses Small Language Models (SLMs) with machine learning techniques in the platform to accurately evaluate and measure the performance of LLMs."}),"\n",(0,n.jsx)(t.h3,{id:"slms",children:"SLMs"}),"\n",(0,n.jsxs)(t.p,{children:["The AlBERTa Small Language Models (SLMs) are built from the ground up to evaluate and detect inaccuracies and hallucinations. These models can be fine-tuned to ",(0,n.jsx)(t.em,{children:"measure correctness"})," for what ",(0,n.jsx)(t.em,{children:"correct"})," means for your specific use case and application."]}),"\n",(0,n.jsx)(t.h5,{id:"alberta-512",children:"AlBERTa-512"}),"\n",(0,n.jsxs)(t.p,{children:["Description:\nContext Length: 512 token context\nOptimized Tasks: ",(0,n.jsx)(t.em,{children:"Detecting inaccuracies, Detecting hallucinations, and Measuring Correctness"})]}),"\n",(0,n.jsx)(t.h5,{id:"alberta-lc-8k",children:"AlBERTa-LC-8k"}),"\n",(0,n.jsxs)(t.p,{children:["Description:\nContext Length: 8192 token context\nOptimized Tasks: ",(0,n.jsx)(t.em,{children:"Detecting inaccuracies, Detecting hallucinations, and Measuring Correctness"})]}),"\n",(0,n.jsx)(t.h3,{id:"platform",children:"Platform"}),"\n",(0,n.jsx)(t.p,{children:"The AutoEval fine-tuning platform enables customization of the AlBERTa SLMs to better evaluate and measure your application's performance."}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{src:"https://github.com/user-attachments/assets/5f9b7d24-6e5b-49e4-b333-4e3b0988a6ef",alt:"diagram"})}),"\n",(0,n.jsx)(t.h4,{id:"platform-capabilities",children:"Platform Capabilities"}),"\n",(0,n.jsx)(t.h5,{id:"1-synthetic-data-generation",children:"1. Synthetic Data Generation"}),"\n",(0,n.jsxs)(t.p,{children:["For use cases that have few to no labels or ground truth data, the AutoEval platform provides the capability to synthetically generate labels. ",(0,n.jsx)(t.strong,{children:"Synthetic Data Generation"})," involves using a model to create data that matches what a realistic response would be and matches the underlying distribution of the data. The platform does its initial labeling through a large-language model (LLM) and over time aligns the performance of the synthetic labels to the ground truth data."]}),"\n",(0,n.jsx)(t.h5,{id:"2-fine-tuning",children:"2. Fine-tuning"}),"\n",(0,n.jsxs)(t.p,{children:["Fine-tuning allows you to improve the performance of LastMile AI's models by tuning the performance to your specific data and use case. ",(0,n.jsx)(t.strong,{children:"Fine-tuning"})," is the process of adapting the small language models for specific tasks."]}),"\n",(0,n.jsx)(t.h5,{id:"3-active-learning",children:"3. Active Learning"}),"\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.strong,{children:"Active learning"})," is in which we use an algorithm (an LLM in this case) to interactively label the training data. You can continuously improve the active learning by providing additional samples of ground truth data."]}),"\n",(0,n.jsx)(t.h5,{id:"4-deployment",children:"4. Deployment"}),"\n",(0,n.jsx)(t.p,{children:"The AutoEval platform, AlBERTa models, and the fine-tuned models can be either hosted on the LastMile AI cloud or within your VPC."})]})}function h(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}},9402:(e,t,a)=>{var n=a(8193);!!n.A.canUseDOM&&navigator.platform.startsWith("Mac"),!!n.A.canUseDOM&&navigator.platform.startsWith("Win")},9365:(e,t,a)=>{a(6540);a(4848)},4865:(e,t,a)=>{a(6540),a(2303);a(4848)},8453:(e,t,a)=>{a.d(t,{R:()=>s,x:()=>r});var n=a(6540);const i={},l=n.createContext(i);function s(e){const t=n.useContext(l);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),n.createElement(l.Provider,{value:t},e.children)}}}]);