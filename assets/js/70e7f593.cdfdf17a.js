"use strict";(self.webpackChunklastmile_docs=self.webpackChunklastmile_docs||[]).push([[5529],{55559:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>o,default:()=>m,frontMatter:()=>r,metadata:()=>d,toc:()=>h});var a=n(74848),s=n(28453),l=n(4865),i=n(19365);n(79402);const r={id:"models",title:"Evaluator Models"},o="Evaluator Models",d={id:"autoeval/models",title:"Evaluator Models",description:"AutoEval models for evaluation tasks",source:"@site/docs/autoeval/models.mdx",sourceDirName:"autoeval",slug:"/autoeval/models",permalink:"/autoeval/models",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{id:"models",title:"Evaluator Models"},sidebar:"sidebar",previous:{title:"Fine-tune Evaluators",permalink:"/autoeval/fine-tune"},next:{title:"Create Guardrails",permalink:"/autoeval/guardrails"}},c={},h=[{value:"alBERTa \ud83c\udf41",id:"alberta-",level:2},{value:"Usage Guide",id:"usage-guide",level:2},{value:"Console",id:"console",level:3},{value:"API",id:"api",level:3}];function u(e){const t={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.header,{children:(0,a.jsx)(t.h1,{id:"evaluator-models",children:"Evaluator Models"})}),"\n",(0,a.jsx)(t.p,{children:"AutoEval models for evaluation tasks"}),"\n",(0,a.jsxs)(t.p,{children:["AutoEval ships with small language models (SLMs) optimized for evaluation tasks. The ",(0,a.jsx)(t.a,{href:"/autoeval/metrics",children:"Metrics section"})," lists all out-of-the-box metrics available on the platform."]}),"\n",(0,a.jsxs)(t.p,{children:["In addition, if you need to design your own metric, you can ",(0,a.jsx)(t.a,{href:"/autoeval/fine-tune",children:"fine-tune"})," LastMile's alBERTa \ud83c\udf41 base model to build a custom evaluator."]}),"\n",(0,a.jsx)(t.h2,{id:"alberta-",children:"alBERTa \ud83c\udf41"}),"\n",(0,a.jsxs)(t.p,{children:["alBERTa is a 400M parameter BERT model that has been trained for NLI tasks and optimized for evaluation workfloads.\nIt is particularly good at framing questions in the premise/hypothesis/entailment formulation, and returns a numeric probability score (0->1), which makes it\nparticularly well-suited for computing ",(0,a.jsx)(t.em,{children:"metrics"}),"."]}),"\n",(0,a.jsx)(t.p,{children:"Key value props:"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.strong,{children:"small"})," -- 400M parameters small"]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.strong,{children:"fast"})," -- can run inference ",(0,a.jsx)("u",{children:"on CPU"})," in < 300ms"]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.strong,{children:"customizable"})," -- fine-tune for custom evaluation tasks"]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.strong,{children:"self-hostable"})," -- available for ",(0,a.jsx)(t.a,{href:"/deployment",children:"VPC deployment"})]}),"\n"]}),"\n",(0,a.jsx)(t.p,{children:"There are two variants in the alBERTa model family:"}),"\n",(0,a.jsxs)(t.table,{children:[(0,a.jsx)(t.thead,{children:(0,a.jsxs)(t.tr,{children:[(0,a.jsx)(t.th,{children:"model"}),(0,a.jsx)(t.th,{children:"context window"}),(0,a.jsx)(t.th,{children:"latency"}),(0,a.jsx)(t.th,{children:"fine-tune"}),(0,a.jsx)(t.th,{children:"description"})]})}),(0,a.jsxs)(t.tbody,{children:[(0,a.jsxs)(t.tr,{children:[(0,a.jsx)(t.td,{children:"alBERTa-512"}),(0,a.jsx)(t.td,{children:"512 tokens"}),(0,a.jsx)(t.td,{children:"<10ms"}),(0,a.jsx)(t.td,{children:"\u2705"}),(0,a.jsx)(t.td,{children:"512-token context variant, available for fine-tuning, and specialized for evaluation tasks (e.g. faithfulness)"})]}),(0,a.jsxs)(t.tr,{children:[(0,a.jsx)(t.td,{children:"alBERTa-LC-8k"}),(0,a.jsx)(t.td,{children:"8192 tokens"}),(0,a.jsx)(t.td,{children:"<400ms"}),(0,a.jsx)(t.td,{}),(0,a.jsx)(t.td,{children:"Long-context window variant that can scale to 128k+ tokens using a scaled dot-product attention layer"})]})]})]}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"alBERTa",src:n(73315).A+"",width:"1528",height:"1032"})}),"\n",(0,a.jsx)(t.h2,{id:"usage-guide",children:"Usage Guide"}),"\n",(0,a.jsxs)(t.p,{children:["Running evals is possible both from the ",(0,a.jsx)(t.a,{href:"https://lastmileai.dev/models",children:"Model Console"})," dashboard as well as the API."]}),"\n",(0,a.jsx)(t.h3,{id:"console",children:"Console"}),"\n",(0,a.jsxs)(t.p,{children:["You can run a one-off evaluation from the model playground. Click any model in the ",(0,a.jsx)(t.a,{href:"https://lastmileai.dev/models",children:"Model Console"}),".\nClick ",(0,a.jsx)(t.code,{children:"Run Model"})," (the play button) to compute a score on some provided data."]}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"Model Playground",src:n(6569).A+"",width:"2674",height:"972"})}),"\n",(0,a.jsx)(t.admonition,{type:"info",children:(0,a.jsxs)(t.p,{children:["Depending on what metric the model calculates, it will accept different input fields. For example, ",(0,a.jsx)(t.code,{children:"Faithfulness"})," measures the faithfulness of the ",(0,a.jsx)(t.code,{children:"output"})," to the ",(0,a.jsx)(t.code,{children:"ground_truth"})," (i.e. context provided)\ngiven the ",(0,a.jsx)(t.code,{children:"input"}),". On the other hand, ",(0,a.jsx)(t.code,{children:"Summarization"})," measures the quality of the ",(0,a.jsx)(t.code,{children:"output"})," summary given the ",(0,a.jsx)(t.code,{children:"input"})," (no ground_truth needed)."]})}),"\n",(0,a.jsx)(t.h3,{id:"api",children:"API"}),"\n",(0,a.jsxs)(t.p,{children:["Reference models by their ",(0,a.jsx)(t.code,{children:"name"})," or ",(0,a.jsx)(t.code,{children:"id"})," (both are available from the console. For example, the ",(0,a.jsx)(t.code,{children:"Faithfulness"})," model can be referenced by its name, or its id ",(0,a.jsx)(t.code,{children:"cm2plr07q000ipkr4o8qhj4oe"}),")."]}),"\n",(0,a.jsxs)(l.A,{groupId:"first-api-request",children:[(0,a.jsx)(i.default,{value:"python",children:(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'from lastmile.lib.auto_eval import AutoEval, Metric\nimport pandas as pd\n\nclient = AutoEval(api_token="api_token_if_LASTMILE_API_TOKEN_not_set")\n\nquery = "Where did the author grow up?"\nexpected_response = "England"\nllm_response = "France"\n\n# Evaluate data in a dataframe\ndata_result_df = client.evaluate_data(\n  data=pd.DataFrame({\n      "input": [query],\n      "output": [llm_response],\n      "ground_truth": [expected_response]\n  }),\n  metrics=[Metric(name="Faithfulness")]\n)\n\n# Evaluate data in a Dataset\ndataset_result_df = client.evaluate_dataset(\n  dataset_id=dataset_id, \n  metrics=[Metric(id="cm2plr07q000ipkr4o8qhj4oe"), Metric(name="Summarization")]\n)\n'})})}),(0,a.jsx)(i.default,{value:"node.js",children:(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-typescript",children:'import { AutoEval, Metric } from "lastmile/lib/auto_eval";\n\nconst client = new AutoEval({\n  apiKey: "api_token_if_LASTMILE_API_TOKEN_not_set",\n});\n\nconst query = "Where did the author grow up?";\nconst expectedResponse = "England";\nconst llmResponse = "France";\n\n// Evaluate data using a direct array of DataRows\nconst dataResult = await client.evaluateData(\n  [\n    {\n      input: query,\n      output: llmResponse,\n      ground_truth: expectedResponse,\n    },\n  ],\n  [{ name: "Faithfulness" }] // Metrics\n);\n\nconsole.table(dataResult);\n\n// Evaluate data in a dataset\nconst datasetId = "your_dataset_id"; // Replace with your dataset ID\nconst datasetResult = await client.evaluateDataset(\n    datasetId,\n    /*metrics*/ [\n      { id: "cm2plr07q000ipkr4o8qhj4oe" }, // Metric by ID\n      { name: "Summarization" }, // Metric by name\n    ]\n);\n\nconsole.table(datasetResult);\n'})})})]}),"\n",(0,a.jsxs)(t.p,{children:["You can reference any metric by its name as it appears in the ",(0,a.jsx)(t.a,{href:"https://lastmileai.dev/models",children:"Model Console"}),".\nAccepted values include:"]}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsx)(t.li,{children:(0,a.jsx)(t.code,{children:'Metric(name="Faithfulness")'})}),"\n",(0,a.jsx)(t.li,{children:(0,a.jsx)(t.code,{children:'Metric(name="Relevance")'})}),"\n",(0,a.jsx)(t.li,{children:(0,a.jsx)(t.code,{children:'Metric(name="Summarization")'})}),"\n",(0,a.jsx)(t.li,{children:(0,a.jsx)(t.code,{children:'Metric(name="Toxicity")'})}),"\n",(0,a.jsx)(t.li,{children:(0,a.jsx)(t.code,{children:'Metric(name="Answer Correctness")'})}),"\n"]}),"\n",(0,a.jsx)(t.admonition,{type:"tip",children:(0,a.jsxs)(t.p,{children:["You can use the same method to run inference on ",(0,a.jsx)(t.a,{href:"/autoeval/fine-tune",children:"fine-tuned evaluator models"}),". Simply refer to them by their ",(0,a.jsx)(t.code,{children:"name"})," or ",(0,a.jsx)(t.code,{children:"id"}),"."]})}),"\n",(0,a.jsx)(t.admonition,{type:"info",children:(0,a.jsxs)(t.p,{children:["Since alBERTa \ud83c\udf41 models are small and fast, you can run them ",(0,a.jsx)(t.strong,{children:"online"})," as guardrails. ",(0,a.jsx)(t.a,{href:"/autoeval/guardrails",children:"Learn more"})," or follow this in-depth ",(0,a.jsx)(t.a,{href:"https://github.com/lastmile-ai/lastmile-docs/blob/main/cookbook/RAG_Guardrails.ipynb",children:"guide"}),"."]})})]})}function m(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(u,{...e})}):u(e)}},79402:(e,t,n)=>{var a=n(38193);!!a.default.canUseDOM&&navigator.platform.startsWith("Mac"),!!a.default.canUseDOM&&navigator.platform.startsWith("Win")},4865:(e,t,n)=>{n.d(t,{A:()=>m});var a=n(96540),s=n(18215),l=n(23104),i=n(47751),r=n(92303);const o={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var d=n(74848);function c(e){let{className:t,block:n,selectedValue:a,selectValue:i,tabValues:r}=e;const c=[],{blockElementScrollPositionUntilNextRender:h}=(0,l.a_)(),u=e=>{const t=e.currentTarget,n=c.indexOf(t),s=r[n].value;s!==a&&(h(t),i(s))},m=e=>{let t=null;switch(e.key){case"Enter":u(e);break;case"ArrowRight":{const n=c.indexOf(e.currentTarget)+1;t=c[n]??c[0];break}case"ArrowLeft":{const n=c.indexOf(e.currentTarget)-1;t=c[n]??c[c.length-1];break}}t?.focus()};return(0,d.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,s.A)("tabs",{"tabs--block":n},t),children:r.map((e=>{let{value:t,label:n,attributes:l}=e;return(0,d.jsx)("li",{role:"tab",tabIndex:a===t?0:-1,"aria-selected":a===t,ref:e=>c.push(e),onKeyDown:m,onClick:u,...l,className:(0,s.A)("tabs__item",o.tabItem,l?.className,{"tabs__item--active":a===t}),children:n??t},t)}))})}function h(e){let{lazy:t,children:n,selectedValue:l}=e;const i=(Array.isArray(n)?n:[n]).filter(Boolean);if(t){const e=i.find((e=>e.props.value===l));return e?(0,a.cloneElement)(e,{className:(0,s.A)("margin-top--md",e.props.className)}):null}return(0,d.jsx)("div",{className:"margin-top--md",children:i.map(((e,t)=>(0,a.cloneElement)(e,{key:t,hidden:e.props.value!==l})))})}function u(e){const t=(0,i.u)(e);return(0,d.jsxs)("div",{className:(0,s.A)("tabs-container",o.tabList),children:[(0,d.jsx)(c,{...t,...e}),(0,d.jsx)(h,{...t,...e})]})}function m(e){const t=(0,r.default)();return(0,d.jsx)(u,{...e,children:(0,i.v)(e.children)},String(t))}},73315:(e,t,n)=>{n.d(t,{A:()=>a});const a=n.p+"assets/images/alberta-d5c637f53ed31f4328af7e2318e1bd46.png"},6569:(e,t,n)=>{n.d(t,{A:()=>a});const a=n.p+"assets/images/playground_quickstart-1c8b26a79818e98277cd00bdb70511aa.png"}}]);