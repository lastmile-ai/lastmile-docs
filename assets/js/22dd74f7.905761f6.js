"use strict";(self.webpackChunklastmile_docs=self.webpackChunklastmile_docs||[]).push([[1567],{55226:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"sidebar":[{"type":"link","label":"Introduction","href":"/","docId":"overview","unlisted":false},{"type":"link","label":"Quickstart","href":"/quickstart","docId":"quickstart","unlisted":false},{"type":"category","label":"AutoEval Developer Platform","items":[{"type":"link","label":"Introduction","href":"/autoeval/autoeval-intro","docId":"autoeval/autoeval-intro","unlisted":false},{"type":"link","label":"Evaluation Metrics","href":"/autoeval/metrics","docId":"autoeval/metrics","unlisted":false},{"type":"category","label":"Manage Datasets","items":[{"type":"link","label":"Example Datasets","href":"/autoeval/datasets/example-datasets","docId":"autoeval/datasets/example-datasets","unlisted":false},{"type":"link","label":"Create Synthetic Datasets","href":"/autoeval/datasets/synthetic-datasets","docId":"autoeval/datasets/synthetic-datasets","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/autoeval/datasets"},{"type":"category","label":"LLM Judge Labeling","items":[{"type":"link","label":"Active Learning","href":"/autoeval/labeling/active-learning","docId":"autoeval/labeling/active-learning","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/autoeval/labeling"},{"type":"link","label":"Fine-tune Evaluation Models","href":"/autoeval/fine-tune","docId":"autoeval/fine-tune","unlisted":false},{"type":"link","label":"Models","href":"/autoeval/models","docId":"autoeval/models","unlisted":false},{"type":"link","label":"Create Guardrails","href":"/autoeval/guardrails","docId":"autoeval/guardrails","unlisted":false}],"collapsible":true,"collapsed":true,"href":"/autoeval/"},{"type":"link","label":"SDK","href":"/sdk","docId":"sdk","unlisted":false},{"type":"category","label":"API","items":[{"type":"link","label":"Introduction","href":"/api/lastmile-ai-rest-api","docId":"api/lastmile-ai-rest-api","unlisted":false},{"type":"category","label":"Dataset","items":[{"type":"link","label":"Create Dataset","href":"/api/dataset-create","className":"api-method post","docId":"api/dataset-create","unlisted":false},{"type":"link","label":"Upload Dataset File","href":"/api/dataset-upload-file","className":"api-method post","docId":"api/dataset-upload-file","unlisted":false},{"type":"link","label":"Finalize Single Dataset File Upload","href":"/api/dataset-finalize-single-file-upload","className":"api-method post","docId":"api/dataset-finalize-single-file-upload","unlisted":false},{"type":"link","label":"Get Dataset","href":"/api/dataset-get","className":"api-method post","docId":"api/dataset-get","unlisted":false},{"type":"link","label":"Get Dataset Download URL","href":"/api/dataset-get-download-url","className":"api-method post","docId":"api/dataset-get-download-url","unlisted":false},{"type":"link","label":"Get Dataset View","href":"/api/dataset-get-view","className":"api-method post","docId":"api/dataset-get-view","unlisted":false},{"type":"link","label":"List Datasets","href":"/api/dataset-list","className":"api-method post","docId":"api/dataset-list","unlisted":false},{"type":"link","label":"Refine Labels","href":"/api/dataset-refine-labels","className":"api-method post","docId":"api/dataset-refine-labels","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Evaluation","items":[{"type":"link","label":"Evaluate","href":"/api/evaluate","className":"api-method post","docId":"api/evaluate","unlisted":false},{"type":"link","label":"Evaluate Dataset","href":"/api/evaluate-dataset","className":"api-method post","docId":"api/evaluate-dataset","unlisted":false},{"type":"link","label":"List Metrics","href":"/api/list-metrics","className":"api-method post","docId":"api/list-metrics","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Fine-tune Job","items":[{"type":"link","label":"Create Fine Tune Job","href":"/api/fine-tune-create","className":"api-method post","docId":"api/fine-tune-create","unlisted":false},{"type":"link","label":"Submit Fine Tune Job","href":"/api/fine-tune-submit","className":"api-method post","docId":"api/fine-tune-submit","unlisted":false},{"type":"link","label":"Get Fine-tune Job Status","href":"/api/fine-tune-get-status","className":"api-method post","docId":"api/fine-tune-get-status","unlisted":false},{"type":"link","label":"List Fine-tune Jobs","href":"/api/fine-tune-list","className":"api-method post","docId":"api/fine-tune-list","unlisted":false},{"type":"link","label":"List Base Models","href":"/api/fine-tune-list-base-models","className":"api-method post","docId":"api/fine-tune-list-base-models","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"LLM Judge Labeling","items":[{"type":"link","label":"Create LLM Judge labeling Job","href":"/api/llm-judge-create","className":"api-method post","docId":"api/llm-judge-create","unlisted":false},{"type":"link","label":"Submit LLM Judge labeling Job","href":"/api/llm-judge-submit","className":"api-method post","docId":"api/llm-judge-submit","unlisted":false},{"type":"link","label":"Get LLM Judge labeling Job Status","href":"/api/llm-judge-get-status","className":"api-method post","docId":"api/llm-judge-get-status","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsible":true,"collapsed":true,"href":"/category/api"},{"type":"link","label":"VPC Deployment","href":"/deployment","docId":"deployment","unlisted":false},{"type":"category","label":"Guides","items":[{"type":"link","label":"Multi-agent evaluation","href":"/guides/multi-agent-evaluation","docId":"guides/multi-agent-evaluation","unlisted":false},{"type":"link","label":"RAG Evaluation","href":"/guides/rag-evaluation","docId":"guides/rag-evaluation","unlisted":false},{"type":"link","label":"Realtime Guardrails","href":"/guides/guardrails-guide","docId":"guides/guardrails-guide","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/category/guides"},{"type":"link","label":"RAG Workbench","description":"Experimentation and monitoring of RAG pipelines","className":"sidebar-link","href":"https://rag.lastmileai.dev"},{"type":"link","label":"Prompt Management","description":"AIConfig is the config-based prompt management framework","className":"sidebar-link","href":"https://aiconfig.lastmileai.dev"}]},"docs":{"api/dataset-create":{"id":"api/dataset-create","title":"Create Dataset","description":"Create a Dataset, such as application traces. Currently limited to a maximum size of 100MB. At least one of \'input\', \'output\' and \'ground_truth\' columns are required.","sidebar":"sidebar"},"api/dataset-finalize-single-file-upload":{"id":"api/dataset-finalize-single-file-upload","title":"Finalize Single Dataset File Upload","description":"Finalize the file upload for a Dataset.","sidebar":"sidebar"},"api/dataset-get":{"id":"api/dataset-get","title":"Get Dataset","description":"Retrieve a Dataset.","sidebar":"sidebar"},"api/dataset-get-download-url":{"id":"api/dataset-get-download-url","title":"Get Dataset Download URL","description":"Description of get_download_url","sidebar":"sidebar"},"api/dataset-get-view":{"id":"api/dataset-get-view","title":"Get Dataset View","description":"View API for a Dataset.","sidebar":"sidebar"},"api/dataset-list":{"id":"api/dataset-list","title":"List Datasets","description":"List Datasets","sidebar":"sidebar"},"api/dataset-refine-labels":{"id":"api/dataset-refine-labels","title":"Refine Labels","description":"Refine labels during active labeling after LLM Judge has done initial labeling.","sidebar":"sidebar"},"api/dataset-upload-file":{"id":"api/dataset-upload-file","title":"Upload Dataset File","description":"Upload a file representing a Dataset.","sidebar":"sidebar"},"api/evaluate":{"id":"api/evaluate","title":"Evaluate","description":"Compute an evaluation metric (or set of metrics) by running inference against evaluator models.","sidebar":"sidebar"},"api/evaluate-dataset":{"id":"api/evaluate-dataset","title":"Evaluate Dataset","description":"Run evaluation on a Dataset.","sidebar":"sidebar"},"api/fine-tune-create":{"id":"api/fine-tune-create","title":"Create Fine Tune Job","description":"Create an evaluator fine-tuning job using a labeled Dataset.","sidebar":"sidebar"},"api/fine-tune-get-status":{"id":"api/fine-tune-get-status","title":"Get Fine-tune Job Status","description":"Get the status of the evaluator fine-tuning job.","sidebar":"sidebar"},"api/fine-tune-list":{"id":"api/fine-tune-list","title":"List Fine-tune Jobs","description":"List evaluator fine-tuning jobs.","sidebar":"sidebar"},"api/fine-tune-list-base-models":{"id":"api/fine-tune-list-base-models","title":"List Base Models","description":"List the base models that can are available for fine-tuning.","sidebar":"sidebar"},"api/fine-tune-submit":{"id":"api/fine-tune-submit","title":"Submit Fine Tune Job","description":"Submit an evaluator fine-tuning job.","sidebar":"sidebar"},"api/lastmile-ai-rest-api":{"id":"api/lastmile-ai-rest-api","title":"LastMile AI REST API","description":"REST API surface for the LastMile platform.","sidebar":"sidebar"},"api/list-metrics":{"id":"api/list-metrics","title":"List Metrics","description":"List the metrics available for evaluation.","sidebar":"sidebar"},"api/llm-judge-create":{"id":"api/llm-judge-create","title":"Create LLM Judge labeling Job","description":"Create an LLM Judge labeling job (also known as pseudo-labeling).","sidebar":"sidebar"},"api/llm-judge-get-status":{"id":"api/llm-judge-get-status","title":"Get LLM Judge labeling Job Status","description":"Get the status of an LLM Judge labeling job.","sidebar":"sidebar"},"api/llm-judge-submit":{"id":"api/llm-judge-submit","title":"Submit LLM Judge labeling Job","description":"Submit an LLM Judge labeling job.","sidebar":"sidebar"},"autoeval/autoeval-intro":{"id":"autoeval/autoeval-intro","title":"Introduction","description":"Testing is the most important step in both LLM application development and monitoring it\'s behavior in production. In Machine Learning and Artificial Intelligence, testing is referred to by different names depending on when and how you test. When testing an LLM application during development, the process is often referred to as Evaluation. When testing an LLM application\'s behavior during production (typically for an real-time/online use case), the testing is referred to as Guardrails. We\'ll cover both of these in more depth.","sidebar":"sidebar"},"autoeval/datasets":{"id":"autoeval/datasets","title":"Manage Datasets","description":"","sidebar":"sidebar"},"autoeval/datasets/example-datasets":{"id":"autoeval/datasets/example-datasets","title":"Example Datasets","description":"","sidebar":"sidebar"},"autoeval/datasets/synthetic-datasets":{"id":"autoeval/datasets/synthetic-datasets","title":"Create Synthetic Datasets","description":"For testing","sidebar":"sidebar"},"autoeval/fine-tune":{"id":"autoeval/fine-tune","title":"Fine-tune Evaluation Models","description":"Fine-tuning allows you to improve the performance of LastMile AI\'s models by tuning the performance to your specific data and use case. Fine-tuning is the process of adapting the small language models for specific tasks. Example use cases from customers:","sidebar":"sidebar"},"autoeval/guardrails":{"id":"autoeval/guardrails","title":"Create Guardrails","description":"Guardrails","sidebar":"sidebar"},"autoeval/index":{"id":"autoeval/index","title":"AutoEval Developer Platform","description":"The AutoEval fine-tuning platform enables customization of the AlBERTa SLMs to better evaluate and measure your application\'s performance.","sidebar":"sidebar"},"autoeval/labeling":{"id":"autoeval/labeling","title":"LLM Judge Labeling","description":"For use cases that have few to no labels or ground truth data, the AutoEval platform provides the capability to synthetically generate labels. Synthetic Data Generation involves using a model to create data that matches what a realistic response would be and matches the underlying distribution of the data. The platform does its initial labeling through a large-language model (LLM) and over time aligns the performance of the synthetic labels to the ground truth data.","sidebar":"sidebar"},"autoeval/labeling/active-learning":{"id":"autoeval/labeling/active-learning","title":"Active Learning","description":"Active learning is in which we use an algorithm (an LLM in this case) to interactively label the training data. You can continuously improve the active learning by providing additional samples of ground truth data.","sidebar":"sidebar"},"autoeval/metrics":{"id":"autoeval/metrics","title":"Evaluation Metrics","description":"Evaluation Metrics are the key to unlocking development velocity and safety in productionizing LLM applications. Metrics measure the performance of your LLM (or Retrieval Augmented Generation - RAG) applications. LastMile AI\'s metrics include hallucination detection, summarization, relevance, q/a, semantic similarity, exact match, bleu, rouge, and toxicity.","sidebar":"sidebar"},"autoeval/models":{"id":"autoeval/models","title":"alBERTa Models","description":"LastMile AI provides small foundational models for evaluating your specific use case for your success metric. If you need additional customization, you can fine-tune these foundational models for your specific use case.","sidebar":"sidebar"},"deployment":{"id":"deployment","title":"VPC Deployment","description":"Hosted by LastMile AI","sidebar":"sidebar"},"guides/guardrails-guide":{"id":"guides/guardrails-guide","title":"Realtime Guardrails","description":"","sidebar":"sidebar"},"guides/multi-agent-evaluation":{"id":"guides/multi-agent-evaluation","title":"Multi-agent evaluation","description":"","sidebar":"sidebar"},"guides/rag-evaluation":{"id":"guides/rag-evaluation","title":"RAG Evaluation","description":"","sidebar":"sidebar"},"overview":{"id":"overview","title":"Introduction","description":"LastMile is the full-stack developer platform to debug, evaluate and improve LLM applications. We make it easy to fine-tune custom evaluators, set up guardrails & monitor app performance.","sidebar":"sidebar"},"quickstart":{"id":"quickstart","title":"Quickstart","description":"Welcome to the quickstart for getting started with LastMile AI\'s AutoEval platform! This guide will walk you through the basics of the platform.","sidebar":"sidebar"},"release-notes":{"id":"release-notes","title":"Release Notes","description":"Release Notes"},"release-notes/2024-11-07-release":{"id":"release-notes/2024-11-07-release","title":"Introducing AutoEval","description":"Nov 7, 2024"},"sdk":{"id":"sdk","title":"SDK","description":"PyPI","sidebar":"sidebar"},"workbooks":{"id":"workbooks","title":"AI Workbooks","description":"Workbooks are interactive documents that combine responses from generative AI models to create unique AI-powered applications and workflows. A workbook enables you to string together various generative AI models to build powerful applications. In a workbook, you can connect text, image, and audio models in a single environment."}}}}')}}]);